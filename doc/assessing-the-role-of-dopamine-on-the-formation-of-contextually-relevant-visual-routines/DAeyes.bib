@article{aggarwalRolePhasicDopamine2011,
  title = {A {{Role}} for {{Phasic Dopamine Neuron Firing}} in {{Habit Learning}}},
  author = {Aggarwal, Mayank and Wickens, Jeffery R.},
  year = {2011},
  month = dec,
  journal = {Neuron},
  volume = {72},
  number = {6},
  pages = {892--894},
  issn = {0896-6273},
  urldate = {2022-07-12},
  abstract = {In this issue of Neuron, Wang et~al. (2011) show that mice with dopamine neuron-specific NMDAR1 deletion have attenuated phasic dopamine neuron firing and a deficit in habit learning. These findings indicate that brain regions sensitive to phasic dopamine signals may underlie habit learning.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/CIDP9VSU/S0896627311010488.html}
}

@article{albinMissingShortLong2017,
  title = {The {{Missing}}, {{The Short}}, and {{The Long}}: {{L-Dopa Responses}} and {{Dopamine Actions}}},
  shorttitle = {The {{Missing}}, {{The Short}}, and {{The Long}}},
  author = {Albin, Roger L. and Leventhal, Daniel K.},
  year = {2017},
  month = jul,
  journal = {Annals of neurology},
  volume = {82},
  number = {1},
  pages = {4--19},
  issn = {0364-5134},
  urldate = {2023-04-19},
  abstract = {We attempt to correlate the clinical pharmacology of dopamine replacement therapy (DRT) in Parkinson Disease with known features of striatal dopamine actions. Despite its obvious impact, DRT does not normalize motor function, likely due to disrupted phasic dopaminergic signaling. The DRT Short Duration Response is likely a permissive-paracrine effect, possibly resulting from dopaminergic support of corticostriate synaptic plasticity. The DRT Long Duration Response may result from mimicry of tonic dopamine signaling regulation of movement vigor. Our understanding of dopamine actions does not explain important aspects of DRT clinical pharmacology. Reducing these knowledge gaps provides opportunities to improve understanding of dopamine actions and symptomatic treatment of Parkinson disease.},
  pmcid = {PMC5526730},
  pmid = {28543679},
  file = {/home/kelly/Zotero/storage/NLGVUBQK/Albin and Leventhal - 2017 - The Missing, The Short, and The Long L-Dopa Respo.pdf}
}

@article{amitaOptogeneticManipulationValuecoding2020b,
  title = {Optogenetic Manipulation of a Value-Coding Pathway from the Primate Caudate Tail Facilitates Saccadic Gaze Shift},
  author = {Amita, Hidetoshi and Kim, Hyoung F. and Inoue, Ken-ichi and Takada, Masahiko and Hikosaka, Okihide},
  year = {2020},
  month = apr,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {1876},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  urldate = {2023-04-19},
  abstract = {In the primate basal ganglia, the caudate tail (CDt) encodes the historical values (good or bad) of visual objects (i.e., stable values), and electrical stimulation of CDt evokes saccadic eye movements. However, it is still unknown how output from CDt conveys stable value signals to govern behavior. Here, we apply a pathway-selective optogenetic manipulation to elucidate how such value information modulates saccades. We express channelrhodopsin-2 in CDt delivered by viral vector injections. Selective optical activation of CDt-derived terminals in the substantia nigra pars reticulata (SNr) inhibits SNr neurons. Notably, these SNr neurons show inhibitory responses to good objects. Furthermore, the optical stimulation causes prolonged excitation of visual-saccadic neurons in the superior colliculus (SC), and induces contralateral saccades. These SC neurons respond more strongly to good than to bad objects in the contralateral hemifield. The present results demonstrate that CDt facilitates saccades toward good objects by serial inhibitory pathways through SNr.},
  copyright = {2020 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
  langid = {english},
  keywords = {Basal ganglia,Decision,Neural circuits},
  file = {/home/kelly/Zotero/storage/BS4L4YYF/Amita et al. - 2020 - Optogenetic manipulation of a value-coding pathway.pdf}
}

@article{andreuBehavioralElectrophysiologicalEvidence2017,
  title = {Behavioral and {{Electrophysiological Evidence}} of {{Enhanced Performance Monitoring}} in {{Meditators}}},
  author = {Andreu, Catherine I. and {Mo{\"e}nne-Loccoz}, Crist{\'o}bal and L{\'o}pez, Vladimir and Slagter, Heleen A. and Franken, Ingmar H. A. and Cosmelli, Diego},
  year = {2017},
  month = dec,
  journal = {Mindfulness},
  volume = {8},
  number = {6},
  pages = {1603--1614},
  issn = {1868-8535},
  urldate = {2023-06-23},
  abstract = {Performance monitoring\textemdash the ability to monitor ongoing performance to detect and correct errors\textemdash is a core component of cognitive control. Impairments in performance monitoring have been associated with several psychiatric disorders, including attention deficit hyperactivity disorder and substance use disorder. Recent research indicates that the practice of meditation, as a mental training technique, may improve cognitive control. However, if and to what extent regular long-term meditation practice may enhance performance monitoring is currently unknown. The present study examined effects of meditation practice on behavioral and electrophysiological indices of performance monitoring. A group of meditators and an experience-matched active control group (non-meditator athletes) performed an Eriksen-Flanker task while their brain activity was recorded using electroencephalography (EEG). Behaviorally, meditators made significantly fewer errors than controls on incongruent trials. EEG analyses revealed a general increase in the amplitude of two brain potentials associated with performance monitoring\textemdash the error negativity (Ne) or error-related negativity (ERN) and correct-related negativity (CRN)\textemdash in meditators compared to controls. These findings, which are indicative of enhanced performance monitoring in meditators, corroborate the idea that meditation could be a recommendable practice to train and improve cognitive control, specifically performance monitoring.},
  langid = {english},
  keywords = {Cognitive control,EEG,Error-related negativity,Meditation,Performance monitoring},
  file = {/home/kelly/Zotero/storage/IPVDDH9F/Andreu et al. - 2017 - Behavioral and Electrophysiological Evidence of En.pdf}
}

@article{anichaCognitiveViewTrait2012,
  title = {Toward a {{Cognitive View}} of {{Trait Mindfulness}}: {{Distinct Cognitive Skills Predict Its Observing}} and {{Nonreactivity Facets}}},
  shorttitle = {Toward a {{Cognitive View}} of {{Trait Mindfulness}}},
  author = {Anicha, Cali L. and Ode, Scott and Moeller, Sara K. and Robinson, Michael D.},
  year = {2012},
  journal = {Journal of Personality},
  volume = {80},
  number = {2},
  pages = {255--285},
  issn = {1467-6494},
  urldate = {2023-06-02},
  abstract = {Dispositional variations in mindfulness and its facets have garnered considerable recent interest in the clinical and personality literatures. Theoretically, high mindful individuals have been characterized as more attuned to momentary sensations and perceptions and/or better able to execute behavior in a controlled manner, yet data of this relatively cognitive type have not been reported. In addition, perceptual attunement and executive control are distinct skills that may underlie, or at least correlate with, distinct facets of mindfulness. In 3 studies involving college students (N = 297), support for the latter idea was found. Individuals high in the observing (but not nonreactivity) facet of mindfulness demonstrated superior perceptual abilities in visual working memory (Study 1) and temporal order (Study 2) tasks. On the other hand, individuals high in the nonreactivity (but not observing) facet of mindfulness exhibited greater cognitive control flexibility (Study 3). Implications for understanding the cognitive basis of mindfulness facets are discussed.},
  copyright = {\textcopyright{} 2011 The Authors. Journal of Personality \textcopyright{} 2012, Wiley Periodicals, Inc},
  langid = {english},
  file = {/home/kelly/Zotero/storage/6V7IKD4F/Anicha et al. - 2012 - Toward a Cognitive View of Trait Mindfulness Dist.pdf;/home/kelly/Zotero/storage/XREETEL5/j.1467-6494.2011.00722.html}
}

@article{ashbyCorticalBasalGanglia2010,
  title = {Cortical and Basal Ganglia Contributions to Habit Learning and Automaticity},
  author = {Ashby, F. Gregory and Turner, Benjamin O. and Horvitz, Jon C.},
  year = {2010},
  month = may,
  journal = {Trends in Cognitive Sciences},
  volume = {14},
  number = {5},
  pages = {208--215},
  issn = {1364-6613},
  urldate = {2022-10-24},
  abstract = {In the 20th century it was thought that novel behaviors are mediated primarily in cortex and that the development of automaticity is a process of transferring control to subcortical structures. However, evidence supports the view that subcortical structures, such as the striatum, make significant contributions to initial learning. More recently, there has been increasing evidence that neurons in the associative striatum are selectively activated during early learning, whereas those in the sensorimotor striatum are more active after automaticity has developed. At the same time, other recent reports indicate that automatic behaviors are striatum- and dopamine-independent, and might be mediated entirely within cortex. Resolving this apparent conflict should be a major goal of future research.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/BFH6HQCS/Ashby et al. - 2010 - Cortical and basal ganglia contributions to habit .pdf;/home/kelly/Zotero/storage/6PUFM9L6/S1364661310000306.html}
}

@misc{asterImpairedFlexibleReward2023,
  title = {Impaired Flexible Reward Learning Is Associated with Blunted Reinforcement Sensitivity and Attenuated Learning and Choice Signals in Ventral Striatum and Parietal Cortex of {{ADHD}} Patients},
  author = {Aster, Hans-Christoph and Waltmann, Maria and Busch, Anika and Romanos, Marcel and Gamer, Matthias and van Noort, Betteke Maria and Beck, Anne and Kappel, Viola and Deserno, Lorenz},
  year = {2023},
  month = apr,
  pages = {2023.04.14.23288555},
  publisher = {{medRxiv}},
  urldate = {2023-04-24},
  abstract = {Reward-based learning and decision-making are prime candidates to understand symptoms of attention deficit hyperactivity disorder (ADHD). However, only limited evidence is available regarding the neurocomputational underpinnings of the alterations seen in ADHD. This particularly concerns the flexible behavioral adaption in dynamically changing environments, which is challenging for individuals with ADHD. One previous study points to elevated choice switching in adolescent ADHD, which was accompanied by disrupted learning signals in medial prefrontal cortex. In the present study, we investigated young adults with ADHD (n=17, 18-32 years) and age and sex matched controls (n=17, 18-30 years) using a probabilistic reversal learning experiment during functional magnetic resonance imaging (fMRI). The task requires continuous learning to guide flexible behavioral adaptation to changing reward contingencies. To disentangle the neurocomputational underpinnings of the behavioral data, we used detailed reinforcement learning (RL) models, which informed the analysis of fMRI data. ADHD patients performed worse than controls particularly in trials before reversals, i.e., when reward contingencies were stable. This pattern resulted from `noisy' choice switching regardless of previous feedback. RL modelling showed decreased reinforcement sensitivity and enhanced learning rates for negative feedback in ADHD patients. At the neural level, this was reflected in diminished representation of choice probability in the left posterior parietal cortex in ADHD. Moreover, modelling showed a marginal reduction of learning about the unchosen option, which was paralleled by an equally marginal reduction in learning signals incorporating the unchosen option in the left ventral striatum. Taken together, we show that flexible behavioral adaptation in the context of dynamically changing reward contingencies is impaired in ADHD. This is due to excessive choice switching (`hyper-flexibility'), which can be detrimental or beneficial depending on the learning environment. Computationally, this results from blunted sensitivity to reinforcement. We detected neural correlates of this blunted sensitivity to reinforcement in the attention-control network, specifically in the parietal cortex. These neurocomputational findings are promising but remain preliminary due to the relatively small sample size.},
  archiveprefix = {medRxiv},
  copyright = {\textcopyright{} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/home/kelly/Zotero/storage/K8HX9Q7R/Aster et al. - 2023 - Impaired flexible reward learning is associated wi.pdf}
}

@article{baerUsingSelfReportAssessment2006,
  title = {Using {{Self-Report Assessment Methods}} to {{Explore Facets}} of {{Mindfulness}}},
  author = {Baer, Ruth A. and Smith, Gregory T. and Hopkins, Jaclyn and Krietemeyer, Jennifer and Toney, Leslie},
  year = {2006},
  month = mar,
  journal = {Assessment},
  volume = {13},
  number = {1},
  pages = {27--45},
  publisher = {{SAGE Publications Inc}},
  issn = {1073-1911},
  urldate = {2022-09-16},
  abstract = {The authors examine the facet structure of mindfulness using five recently developed mindfulness questionnaires. Two large samples of undergraduate students completed mindfulness questionnaires and measures of other constructs. Psychometric properties of the mindfulness questionnaires were examined, including internal consistency and convergent and discriminant relationships with other variables. Factor analyses of the combined pool of items from the mindfulness questionnaires suggested that collectively they contain five clear, interpretable facets of mindfulness. Hierarchical confirmatory factor analyses suggested that at least four of the identified factors are components of an overall mindfulness construct and that the factor structure of mindfulness may vary with meditation experience. Mindfulness facets were shown to be differentially correlated in expected ways with several other constructs and to have incremental validity in the prediction of psychological symptoms. Findings suggest that conceptualizing mindfulness as a multifaceted construct is helpful in understanding its components and its relationships with other variables.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/TLCM79Z9/Baer et al. - 2006 - Using Self-Report Assessment Methods to Explore Fa.pdf}
}

@article{bar-gadReinforcementdrivenDimensionalityReduction2000,
  title = {Reinforcement-Driven Dimensionality Reduction--a Model for Information Processing in the Basal Ganglia},
  author = {{Bar-Gad}, I. and {Havazelet-Heimer}, G. and Goldberg, J. A. and Ruppin, E. and Bergman, H.},
  year = {2000},
  journal = {Journal of Basic and Clinical Physiology and Pharmacology},
  volume = {11},
  number = {4},
  pages = {305--320},
  issn = {0792-6855},
  abstract = {Although anatomical studies of the basal ganglia show the existence of extensive convergence and lateral inhibitory connections, physiological studies failed to show correlated neural activity or lateral interaction in these nuclei. These seemingly contradictory results could be explained with a model in which the basal ganglia reduce the dimensionality of cortical information using optimal extraction methods. Simulations of this model predict a transient change in the efficacy of the feed-forward and lateral synapses following changes in reinforcement signal, causing an increase in correlated firing rates. This process ultimately restores the steady-state situation with diminished efficacy of lateral inhibition and no correlation of firing. Our experimental results confirm the model's predictions: rate correlations show a drastic decrease between the input stage (cortex) and output stage (pallidum). Moreover, preliminary analysis revealed that pallidal correlations show a transient increase following discrepancies between the animal's predictions and reality. We therefore propose that by using a reinforcement-driven dimensionality reduction process the basal ganglia achieve efficient extraction of cortical salient information that may then be used by the frontal cortex for execution and planning of forthcoming actions.},
  langid = {english},
  pmid = {11248944},
  keywords = {Animals,Basal Ganglia,Cerebral Cortex,Globus Pallidus,Mental Processes,{Models, Neurological},{Neural Networks, Computer},Neurons,Rats,{Reinforcement, Psychology}}
}

@article{barrRandomEffectsStructure2013,
  title = {Random Effects Structure for Confirmatory Hypothesis Testing: {{Keep}} It Maximal},
  shorttitle = {Random Effects Structure for Confirmatory Hypothesis Testing},
  author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  year = {2013},
  month = apr,
  journal = {Journal of Memory and Language},
  volume = {68},
  number = {3},
  pages = {255--278},
  issn = {0749-596X},
  urldate = {2021-07-26},
  abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the `gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond.},
  langid = {english},
  keywords = {Generalization,Linear mixed-effects models,Monte Carlo simulation,Statistics},
  file = {/home/kelly/Zotero/storage/DFMN2XF6/Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf;/home/kelly/Zotero/storage/7JRBYVVU/S0749596X12001180.html}
}

@article{berridgeWhatRoleDopamine1998,
  title = {What Is the Role of Dopamine in Reward: Hedonic Impact, Reward Learning, or Incentive Salience?},
  shorttitle = {What Is the Role of Dopamine in Reward},
  author = {Berridge, K. C. and Robinson, T. E.},
  year = {1998},
  month = dec,
  journal = {Brain Research. Brain Research Reviews},
  volume = {28},
  number = {3},
  pages = {309--369},
  abstract = {What roles do mesolimbic and neostriatal dopamine systems play in reward? Do they mediate the hedonic impact of rewarding stimuli? Do they mediate hedonic reward learning and associative prediction? Our review of the literature, together with results of a new study of residual reward capacity after dopamine depletion, indicates the answer to both questions is 'no'. Rather, dopamine systems may mediate the incentive salience of rewards, modulating their motivational value in a manner separable from hedonia and reward learning. In a study of the consequences of dopamine loss, rats were depleted of dopamine in the nucleus accumbens and neostriatum by up to 99\% using 6-hydroxydopamine. In a series of experiments, we applied the 'taste reactivity' measure of affective reactions (gapes, etc.) to assess the capacity of dopamine-depleted rats for: 1) normal affect (hedonic and aversive reactions), 2) modulation of hedonic affect by associative learning (taste aversion conditioning), and 3) hedonic enhancement of affect by non-dopaminergic pharmacological manipulation of palatability (benzodiazepine administration). We found normal hedonic reaction patterns to sucrose vs. quinine, normal learning of new hedonic stimulus values (a change in palatability based on predictive relations), and normal pharmacological hedonic enhancement of palatability. We discuss these results in the context of hypotheses and data concerning the role of dopamine in reward. We review neurochemical, electrophysiological, and other behavioral evidence. We conclude that dopamine systems are not needed either to mediate the hedonic pleasure of reinforcers or to mediate predictive associations involved in hedonic reward learning. We conclude instead that dopamine may be more important to incentive salience attributions to the neural representations of reward-related stimuli. Incentive salience, we suggest, is a distinct component of motivation and reward. In other words, dopamine systems are necessary for 'wanting' incentives, but not for 'liking' them or for learning new 'likes' and 'dislikes'.},
  langid = {english},
  pmid = {9858756},
  keywords = {Animals,Brain Chemistry,Dopamine,Humans,Learning,Limbic System,Neostriatum,Rats,Reward}
}

@article{berridgeWhatRoleDopamine1998a,
  title = {What Is the Role of Dopamine in Reward: Hedonic Impact, Reward Learning, or Incentive Salience?},
  shorttitle = {What Is the Role of Dopamine in Reward},
  author = {Berridge, K. C. and Robinson, T. E.},
  year = {1998},
  month = dec,
  journal = {Brain Research. Brain Research Reviews},
  volume = {28},
  number = {3},
  pages = {309--369},
  abstract = {What roles do mesolimbic and neostriatal dopamine systems play in reward? Do they mediate the hedonic impact of rewarding stimuli? Do they mediate hedonic reward learning and associative prediction? Our review of the literature, together with results of a new study of residual reward capacity after dopamine depletion, indicates the answer to both questions is 'no'. Rather, dopamine systems may mediate the incentive salience of rewards, modulating their motivational value in a manner separable from hedonia and reward learning. In a study of the consequences of dopamine loss, rats were depleted of dopamine in the nucleus accumbens and neostriatum by up to 99\% using 6-hydroxydopamine. In a series of experiments, we applied the 'taste reactivity' measure of affective reactions (gapes, etc.) to assess the capacity of dopamine-depleted rats for: 1) normal affect (hedonic and aversive reactions), 2) modulation of hedonic affect by associative learning (taste aversion conditioning), and 3) hedonic enhancement of affect by non-dopaminergic pharmacological manipulation of palatability (benzodiazepine administration). We found normal hedonic reaction patterns to sucrose vs. quinine, normal learning of new hedonic stimulus values (a change in palatability based on predictive relations), and normal pharmacological hedonic enhancement of palatability. We discuss these results in the context of hypotheses and data concerning the role of dopamine in reward. We review neurochemical, electrophysiological, and other behavioral evidence. We conclude that dopamine systems are not needed either to mediate the hedonic pleasure of reinforcers or to mediate predictive associations involved in hedonic reward learning. We conclude instead that dopamine may be more important to incentive salience attributions to the neural representations of reward-related stimuli. Incentive salience, we suggest, is a distinct component of motivation and reward. In other words, dopamine systems are necessary for 'wanting' incentives, but not for 'liking' them or for learning new 'likes' and 'dislikes'.},
  langid = {english},
  pmid = {9858756},
  keywords = {Animals,Brain Chemistry,Dopamine,Humans,Learning,Limbic System,Neostriatum,Rats,Reward}
}

@article{beyelerNeuralCorrelatesSparse2019a,
  title = {Neural Correlates of Sparse Coding and Dimensionality Reduction},
  author = {Beyeler, Michael and Rounds, Emily L. and Carlson, Kristofor D. and Dutt, Nikil and Krichmar, Jeffrey L.},
  year = {2019},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {15},
  number = {6},
  pages = {e1006908},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  urldate = {2021-10-20},
  abstract = {Supported by recent computational studies, there is increasing evidence that a wide range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC), an efficient population coding scheme based on dimensionality reduction and sparsity constraints. We review evidence that NSC might be employed by sensory areas to efficiently encode external stimulus spaces, by some associative areas to conjunctively represent multiple behaviorally relevant variables, and possibly by the basal ganglia to coordinate movement. In addition, NSC might provide a useful theoretical framework under which to understand the often complex and nonintuitive response properties of neurons in other brain areas. Although NSC might not apply to all brain areas (for example, motor or executive function areas) the success of NSC-based models, especially in sensory areas, warrants further investigation for neural correlates in other regions.},
  langid = {english},
  keywords = {Basal ganglia,Behavior,Coding mechanisms,Face,Neurons,Sensory perception,Vision,Visual cortex},
  file = {/home/kelly/Zotero/storage/9NK82U5L/Beyeler et al. - 2019 - Neural correlates of sparse coding and dimensional.pdf}
}

@article{bondUseAnalogueScales1974,
  title = {The Use of Analogue Scales in Rating Subjective Feelings},
  author = {Bond, Alyson and Lader, Malcolm},
  year = {1974},
  journal = {British Journal of Medical Psychology},
  volume = {47},
  number = {3},
  pages = {211--218},
  issn = {2044-8341},
  urldate = {2023-03-31},
  langid = {english},
  file = {/home/kelly/Zotero/storage/NWKL59EF/Bond and Lader - 1974 - The use of analogue scales in rating subjective fe.pdf;/home/kelly/Zotero/storage/9FEYAFLH/j.2044-8341.1974.tb02285.html}
}

@article{buckholtzDopaminergicNetworkDifferences2010,
  title = {Dopaminergic Network Differences in Human Impulsivity},
  author = {Buckholtz, Joshua W. and Treadway, Michael T. and Cowan, Ronald L. and Woodward, Neil D. and Li, Rui and Ansari, M. Sib and Baldwin, Ronald M. and Schwartzman, Ashley N. and Shelby, Evan S. and Smith, Clarence E. and Kessler, Robert M. and Zald, David H.},
  year = {2010},
  month = jul,
  journal = {Science (New York, N.Y.)},
  volume = {329},
  number = {5991},
  pages = {532},
  issn = {1095-9203},
  abstract = {Dopamine (DA) has long been implicated in impulsivity, but the precise mechanisms linking human variability in DA signaling to differences in impulsive traits remain largely unknown. By using a dual-scan positron emission tomography approach in healthy human volunteers with amphetamine and the D2/D3 ligand [18F]fallypride, we found that higher levels of trait impulsivity were predicted by diminished midbrain D2/D3 autoreceptor binding and greater amphetamine-induced DA release in the striatum, which was in turn associated with stimulant craving. Path analysis confirmed that the impact of decreased midbrain D2/D3 autoreceptor availability on trait impulsivity is mediated in part through its effect on stimulated striatal DA release.},
  langid = {english},
  pmcid = {PMC3161413},
  pmid = {20671181},
  keywords = {Adolescent,Adult,Amphetamine-Related Disorders,Autoreceptors,Benzamides,Corpus Striatum,Dextroamphetamine,Dopamine,Female,Humans,Impulsive Behavior,Ligands,Male,Positron-Emission Tomography,Pyrrolidines,{Receptors, Dopamine D2},{Receptors, Dopamine D3},Signal Transduction,Substantia Nigra,Tegmentum Mesencephali,Ventral Tegmental Area,Young Adult},
  file = {/home/kelly/Zotero/storage/XQH8VHMC/Buckholtz et al. - 2010 - Dopaminergic network differences in human impulsiv.pdf}
}

@article{bucknerSelfprojectionBrain2007,
  title = {Self-Projection and the Brain},
  author = {Buckner, Randy L. and Carroll, Daniel C.},
  year = {2007},
  month = feb,
  journal = {Trends in Cognitive Sciences},
  volume = {11},
  number = {2},
  pages = {49--57},
  publisher = {{Elsevier}},
  issn = {1364-6613, 1879-307X},
  urldate = {2023-04-19},
  langid = {english},
  pmid = {17188554}
}

@article{budzilloDopaminergicModulationBasal2017,
  title = {Dopaminergic Modulation of Basal Ganglia Output through Coupled Excitation\textendash Inhibition},
  author = {Budzillo, Agata and Duffy, Alison and Miller, Kimberly E. and Fairhall, Adrienne L. and Perkel, David J.},
  year = {2017},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {22},
  pages = {5713--5718},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  urldate = {2021-01-06},
  abstract = {Learning and maintenance of skilled movements require exploration of motor space and selection of appropriate actions. Vocal learning and social context-dependent plasticity in songbirds depend on a basal ganglia circuit, which actively generates vocal variability. Dopamine in the basal ganglia reduces trial-to-trial neural variability when the bird engages in courtship song. Here, we present evidence for a unique, tonically active, excitatory interneuron in the songbird basal ganglia that makes strong synaptic connections onto output pallidal neurons, often linked in time with inhibitory events. Dopamine receptor activity modulates the coupling of these excitatory and inhibitory events in vitro, which results in a dynamic change in the synchrony of a modeled population of basal ganglia output neurons receiving excitatory and inhibitory inputs. The excitatory interneuron thus serves as one biophysical mechanism for the introduction or modulation of neural variability in this circuit.},
  chapter = {Biological Sciences},
  copyright = {\textcopyright{}  . http://www.pnas.org/site/misc/userlicense.xhtml},
  langid = {english},
  pmid = {28507134},
  keywords = {basal ganglia,dopamine,learning,songbird,variability},
  file = {/home/kelly/Zotero/storage/HCZEWPSB/Budzillo et al. - 2017 - Dopaminergic modulation of basal ganglia output th.pdf;/home/kelly/Zotero/storage/I4C2MPXA/5713.html}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  journal = {Journal of statistical software},
  volume = {80},
  pages = {1--28}
}

@article{chakrounDopaminergicModulationExploration2020,
  title = {Dopaminergic Modulation of the Exploration/Exploitation Trade-off in Human Decision-Making},
  author = {Chakroun, Karima and Mathar, David and Wiehler, Antonius and Ganzer, Florian and Peters, Jan},
  editor = {Gershman, Samuel J and Frank, Michael J and Gershman, Samuel J and Averbeck, Bruno B and Pearson, John},
  year = {2020},
  month = jun,
  journal = {eLife},
  volume = {9},
  pages = {e51260},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  urldate = {2023-06-14},
  abstract = {Involvement of dopamine in regulating exploration during decision-making has long been hypothesized, but direct causal evidence in humans is still lacking. Here, we use a combination of computational modeling, pharmacological intervention and functional magnetic resonance imaging to address this issue. Thirty-one healthy male participants performed a restless four-armed bandit task in a within-subjects design under three drug conditions: 150 mg of the dopamine precursor L-dopa, 2 mg of the D2 receptor antagonist haloperidol, and placebo. Choices were best explained by an extension of an established Bayesian learning model accounting for perseveration, directed exploration and random exploration. Modeling revealed attenuated directed exploration under L-dopa, while neural signatures of exploration, exploitation and prediction error were unaffected. Instead, L-dopa attenuated neural representations of overall uncertainty in insula and dorsal anterior cingulate cortex. Our results highlight the computational role of these regions in exploration and suggest that dopamine modulates how this circuit tracks accumulating uncertainty during decision-making.},
  keywords = {computational modeling,decision-making,dopamine,exploration,pharmacological fMRI},
  file = {/home/kelly/Zotero/storage/NVH94A7D/Chakroun et al. - 2020 - Dopaminergic modulation of the explorationexploit.pdf}
}

@article{chenEffectBriefMindfulness2023,
  title = {The Effect of Brief Mindfulness Training on the Micro-Structure of Human Free-Operant Responding: {{Mindfulness}} Affects Stimulus-Driven Responding},
  shorttitle = {The Effect of Brief Mindfulness Training on the Micro-Structure of Human Free-Operant Responding},
  author = {Chen, Xiaosheng and Reed, Phil},
  year = {2023},
  month = jun,
  journal = {Journal of Behavior Therapy and Experimental Psychiatry},
  volume = {79},
  pages = {101821},
  issn = {0005-7916},
  urldate = {2023-06-07},
  abstract = {Background and objectives The current study examines the extent to which mindfulness impacts on operant conditioning processes, and explores the suggestion that mindfulness training serves to make humans more sensitive to the current reinforcement contingencies with which they are presented. In particular, the effect of mindfulness on the micro-structure of human schedule performance was explored. It was expected that mindfulness might impact bout-initiation responding to a greater degree than within-bout responding, premised on the assumption that bout-initiation responses are habitual and not under conscious control, but within-bout responses are goal-directed and conscious. Methods Nonclinical participants experienced one of three brief (15min) interventions: focused attention breathing exercise (mindfulness), an unfocused attention breathing exercises, or no intervention. They then responded on a multiple random ratio (RR) random interval (RI) schedule. Results In the no intervention and unfocused attention groups, overall and within-bout response rates were higher on the RR than the RI schedule, but bout-initiation rates were the same on the two schedules. However, for the mindfulness groups all forms of responding were higher for the RR than the RI schedule. Previous work has noted that habitual, and/or unconscious or fringe-conscious events, are impacted by mindfulness training. Limitations A nonclinical sample may limit generality. Conclusions The current pattern of results suggests that this is also true in schedule-controlled performance, and offers an insight into the manner in which mindfulness alongside conditioning-based interventions, to bring all responses under conscious control.},
  langid = {english},
  keywords = {Actions,Awareness,Habits,Mindfulness,Response micro-structure,Schedules of reinforcement},
  file = {/home/kelly/Zotero/storage/IWGG68LC/Chen and Reed - 2023 - The effect of brief mindfulness training on the mi.pdf;/home/kelly/Zotero/storage/32KDT88P/S0005791622000994.html}
}

@article{chenEffectBriefMindfulness2023a,
  title = {The Effect of Brief Mindfulness Training on the Micro-Structure of Human Free-Operant Responding: {{Mindfulness}} Affects Stimulus-Driven Responding},
  shorttitle = {The Effect of Brief Mindfulness Training on the Micro-Structure of Human Free-Operant Responding},
  author = {Chen, Xiaosheng and Reed, Phil},
  year = {2023},
  month = jun,
  journal = {Journal of Behavior Therapy and Experimental Psychiatry},
  volume = {79},
  pages = {101821},
  issn = {0005-7916},
  urldate = {2023-06-13},
  abstract = {Background and objectives The current study examines the extent to which mindfulness impacts on operant conditioning processes, and explores the suggestion that mindfulness training serves to make humans more sensitive to the current reinforcement contingencies with which they are presented. In particular, the effect of mindfulness on the micro-structure of human schedule performance was explored. It was expected that mindfulness might impact bout-initiation responding to a greater degree than within-bout responding, premised on the assumption that bout-initiation responses are habitual and not under conscious control, but within-bout responses are goal-directed and conscious. Methods Nonclinical participants experienced one of three brief (15min) interventions: focused attention breathing exercise (mindfulness), an unfocused attention breathing exercises, or no intervention. They then responded on a multiple random ratio (RR) random interval (RI) schedule. Results In the no intervention and unfocused attention groups, overall and within-bout response rates were higher on the RR than the RI schedule, but bout-initiation rates were the same on the two schedules. However, for the mindfulness groups all forms of responding were higher for the RR than the RI schedule. Previous work has noted that habitual, and/or unconscious or fringe-conscious events, are impacted by mindfulness training. Limitations A nonclinical sample may limit generality. Conclusions The current pattern of results suggests that this is also true in schedule-controlled performance, and offers an insight into the manner in which mindfulness alongside conditioning-based interventions, to bring all responses under conscious control.},
  langid = {english},
  keywords = {Actions,Awareness,Habits,Mindfulness,Response micro-structure,Schedules of reinforcement},
  file = {/home/kelly/Zotero/storage/ZDBEF744/Chen and Reed - 2023 - The effect of brief mindfulness training on the mi.pdf;/home/kelly/Zotero/storage/9HJE8REL/S0005791622000994.html}
}

@article{chowdhuryDopamineModulatesEpisodic2012,
  title = {Dopamine Modulates Episodic Memory Persistence in Old Age},
  author = {Chowdhury, Rumana and {Guitart-Masip}, Marc and Bunzeck, Nico and Dolan, Raymond J. and D{\"u}zel, Emrah},
  year = {2012},
  month = oct,
  journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  volume = {32},
  number = {41},
  pages = {14193--14204},
  issn = {1529-2401},
  abstract = {Activation of the hippocampus is required to encode memories for new events (or episodes). Observations from animal studies suggest that, for these memories to persist beyond 4-6 h, a release of dopamine generated by strong hippocampal activation is needed. This predicts that dopaminergic enhancement should improve human episodic memory persistence also for events encoded with weak hippocampal activation. Here, using pharmacological functional MRI (fMRI) in an elderly population in which there is a loss of dopamine neurons as part of normal aging, we show this very effect. The dopamine precursor levodopa led to a dose-dependent (inverted U-shape) persistent episodic memory benefit for images of scenes when tested after 6 h, independent of whether encoding-related hippocampal fMRI activity was weak or strong (U-shaped dose-response relationship). This lasting improvement even for weakly encoded events supports a role for dopamine in human episodic memory consolidation, albeit operating within a narrow dose range.},
  langid = {english},
  pmcid = {PMC3734374},
  pmid = {23055489},
  keywords = {Aged,Aging,Cohort Studies,Cross-Over Studies,Dopamine,Dopamine Agents,{Dose-Response Relationship, Drug},Double-Blind Method,Female,Hippocampus,Humans,Levodopa,Magnetic Resonance Imaging,Male,{Memory, Episodic},Photic Stimulation},
  file = {/home/kelly/Zotero/storage/LZW6FBID/Chowdhury et al. - 2012 - Dopamine modulates episodic memory persistence in .pdf}
}

@article{chowdhuryDopamineRestoresReward2013,
  title = {Dopamine Restores Reward Prediction Errors in Old Age},
  author = {Chowdhury, Rumana and {Guitart-Masip}, Marc and Lambert, Christian and Dayan, Peter and Huys, Quentin and D{\"u}zel, Emrah and Dolan, Raymond J.},
  year = {2013},
  month = may,
  journal = {Nature Neuroscience},
  volume = {16},
  number = {5},
  pages = {648--653},
  issn = {1546-1726},
  abstract = {Senescence affects the ability to utilize information about the likelihood of rewards for optimal decision-making. Using functional magnetic resonance imaging in humans, we found that healthy older adults had an abnormal signature of expected value, resulting in an incomplete reward prediction error (RPE) signal in the nucleus accumbens, a brain region that receives rich input projections from substantia nigra/ventral tegmental area (SN/VTA) dopaminergic neurons. Structural connectivity between SN/VTA and striatum, measured by diffusion tensor imaging, was tightly coupled to inter-individual differences in the expression of this expected reward value signal. The dopamine precursor levodopa (L-DOPA) increased the task-based learning rate and task performance in some older adults to the level of young adults. This drug effect was linked to restoration of a canonical neural RPE. Our results identify a neurochemical signature underlying abnormal reward processing in older adults and indicate that this can be modulated by L-DOPA.},
  langid = {english},
  pmcid = {PMC3672991},
  pmid = {23525044},
  keywords = {Adult,Aged,Aging,Alkaloids,Brain,{Conditioning, Operant},Dopamine Agents,Double-Blind Method,Female,Humans,{Image Processing, Computer-Assisted},Levodopa,Magnetic Resonance Imaging,Male,Oxygen,{Reinforcement, Psychology},Reward,Time Factors,Young Adult},
  file = {/home/kelly/Zotero/storage/BETZP7BB/Chowdhury et al. - 2013 - Dopamine restores reward prediction errors in old .pdf}
}

@article{coolsEnhancedImpairedCognitive2001,
  title = {Enhanced or Impaired Cognitive Function in {{Parkinson}}'s Disease as a Function of Dopaminergic Medication and Task Demands},
  author = {Cools, R. and Barker, R. A. and Sahakian, B. J. and Robbins, T. W.},
  year = {2001},
  month = dec,
  journal = {Cerebral Cortex (New York, N.Y.: 1991)},
  volume = {11},
  number = {12},
  pages = {1136--1143},
  issn = {1047-3211},
  abstract = {We investigated how dopamine (DA) systems contribute to cognitive performance in the domain of learning and attentional flexibility by examining effects of withdrawing DA-ergic medication in patients with Parkinson's disease (PD). Medication remediated impairments in switching between two tasks, thought to depend on circuitry connecting the dorsolateral prefrontal cortex and the posterior parietal cortex to the dorsal caudate nucleus, which is profoundly DA-depleted in PD. By contrast, the same medication impaired probabilistic reversal learning that implicates orbitofrontal cortex- ventral striatal circuitry, which is relatively spared of DA loss in PD. Hence, DA-ergic medication improves or impairs cognitive performance depending on the nature of the task and the basal level of DA function in underlying cortico-striatal circuitry.},
  langid = {english},
  pmid = {11709484},
  keywords = {Attention,Caudate Nucleus,Cognition Disorders,Dopamine Agents,Humans,Neural Pathways,Parietal Lobe,Parkinson Disease,Reversal Learning},
  file = {/home/kelly/Zotero/storage/BKWVSM6Z/Cools et al. - 2001 - Enhanced or impaired cognitive function in Parkins.pdf}
}

@article{corbitEffectsRepeatedCocaine2014,
  title = {Effects of {{Repeated Cocaine Exposure}} on {{Habit Learning}} and {{Reversal}} by {{N-Acetylcysteine}}},
  author = {Corbit, Laura H. and Chieng, Billy C. and Balleine, Bernard W.},
  year = {2014},
  month = jul,
  journal = {Neuropsychopharmacology},
  volume = {39},
  number = {8},
  pages = {1893--1901},
  publisher = {{Nature Publishing Group}},
  issn = {1740-634X},
  urldate = {2023-07-04},
  abstract = {Exposure to drugs of abuse can result in a loss of control over both drug- and nondrug-related actions by accelerating the transition from goal-directed to habitual control, an effect argued to reflect changes in glutamate homeostasis. Here we examined whether exposure to cocaine accelerates habit learning and used in vitro electrophysiology to investigate its effects on measures of synaptic plasticity in the dorsomedial (DMS) and dorsolateral (DLS) striatum, areas critical for actions and habits, respectively. We then administered N-acetylcysteine (NAC) in an attempt to normalize glutamate homeostasis and hence reverse the cellular and behavioral effects of cocaine exposure. Rats received daily injections of cocaine (30\,mg/kg) for 6 days and were then trained to lever press for a food reward. We used outcome devaluation and whole-cell patch-clamp electrophysiology to assess the behavioral and cellular effects of cocaine exposure. We then examined the ability of NAC to reverse the effects of cocaine exposure on these measures. Cocaine treatment produced a deficit in goal-directed action, as assessed by outcome devaluation, and increased the frequency of spontaneous and miniature excitatory postsynaptic currents (EPSCs) in the DMS but not in the DLS. Importantly, NAC treatment both normalized EPSC frequency and promoted goal-directed control in cocaine-treated rats. The promotion of goal-directed control has the potential to improve treatment outcomes in human cocaine addicts.},
  copyright = {2014 American College of Neuropsychopharmacology},
  langid = {english},
  keywords = {Addiction,Learning and memory,Pharmacology,Synaptic plasticity},
  file = {/home/kelly/Zotero/storage/4SDZYA2Q/Corbit et al. - 2014 - Effects of Repeated Cocaine Exposure on Habit Lear.pdf}
}

@article{darshanCanonicalNeuralMechanism2017,
  title = {A Canonical Neural Mechanism for Behavioral Variability},
  author = {Darshan, Ran and Wood, William E. and Peters, Susan and Leblois, Arthur and Hansel, David},
  year = {2017},
  month = may,
  journal = {Nature Communications},
  volume = {8},
  number = {1},
  pages = {15415},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  urldate = {2022-07-08},
  abstract = {The ability to generate variable movements is essential for learning and adjusting complex behaviours. This variability has been linked to the temporal irregularity of neuronal activity in the central nervous system. However, how neuronal irregularity actually translates into behavioural variability is unclear. Here we combine modelling, electrophysiological and behavioural studies to address this issue. We demonstrate that a model circuit comprising topographically organized and strongly recurrent neural networks can autonomously generate irregular motor behaviours. Simultaneous recordings of neurons in singing finches reveal that neural correlations increase across the circuit driving song variability, in agreement with the model predictions. Analysing behavioural data, we find remarkable similarities in the babbling statistics of 5\textendash 6-month-old human infants and juveniles from three songbird species and show that our model naturally accounts for these `universal' statistics.},
  copyright = {2017 The Author(s)},
  langid = {english},
  keywords = {Learning and memory,Network models},
  file = {/home/kelly/Zotero/storage/SCQ5RJ2L/Darshan et al. - 2017 - A canonical neural mechanism for behavioral variab.pdf;/home/kelly/Zotero/storage/NFEZEKMP/ncomms15415.html}
}

@book{davids1900buddhist,
  title = {Buddhist Suttas},
  author = {Davids, Thomas William Rhys},
  year = {1900},
  volume = {11},
  publisher = {{Clarendon Press}}
}

@article{desernoDopamineEnhancesModelfree2021a,
  title = {Dopamine Enhances Model-Free Credit Assignment through Boosting of Retrospective Model-Based Inference},
  author = {Deserno, Lorenz and Moran, Rani and Michely, Jochen and Lee, Ying and Dayan, Peter and Dolan, Raymond J},
  editor = {Kahnt, Thorsten and B{\"u}chel, Christian and Cools, Roshan},
  year = {2021},
  month = dec,
  journal = {eLife},
  volume = {10},
  pages = {e67778},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  urldate = {2023-07-03},
  abstract = {Dopamine is implicated in representing model-free (MF) reward prediction errors a as well as influencing model-based (MB) credit assignment and choice. Putative cooperative interactions between MB and MF systems include a guidance of MF credit assignment by MB inference. Here, we used a double-blind, placebo-controlled, within-subjects design to test an hypothesis that enhancing dopamine levels boosts the guidance of MF credit assignment by MB inference. In line with this, we found that levodopa enhanced guidance of MF credit assignment by MB inference, without impacting MF and MB influences directly. This drug effect correlated negatively with a dopamine-dependent change in purely MB credit assignment, possibly reflecting a trade-off between these two MB components of behavioural control. Our findings of a dopamine boost in MB inference guidance of MF learning highlight a novel DA influence on MB-MF cooperative interactions.},
  keywords = {dopamine,model-free/model-based,reinforcement learning},
  file = {/home/kelly/Zotero/storage/JD4FQRN3/Deserno et al. - 2021 - Dopamine enhances model-free credit assignment thr.pdf}
}

@article{desrochersHabitLearningNaive2015,
  title = {Habit {{Learning}} by {{Naive Macaques Is Marked}} by {{Response Sharpening}} of {{Striatal Neurons Representing}} the {{Cost}} and {{Outcome}} of {{Acquired Action Sequences}}},
  author = {Desrochers, Theresa M. and Amemori, Ken-ichi and Graybiel, Ann M.},
  year = {2015},
  month = aug,
  journal = {Neuron},
  volume = {87},
  number = {4},
  pages = {853--868},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  urldate = {2021-01-06},
  langid = {english},
  pmid = {26291166},
  file = {/home/kelly/Zotero/storage/YI9WEVMI/Desrochers et al. - 2015 - Habit Learning by Naive Macaques Is Marked by Resp.pdf;/home/kelly/Zotero/storage/W5X3KVAD/S0896-6273(15)00641-8.html}
}

@article{desrochersMonitoringControlTask2016,
  title = {The {{Monitoring}} and {{Control}} of {{Task Sequences}} in {{Human}} and {{Non-Human Primates}}},
  author = {Desrochers, Theresa M. and Burk, Diana C. and Badre, David and Sheinberg, David L.},
  year = {2016},
  journal = {Frontiers in Systems Neuroscience},
  volume = {9},
  issn = {1662-5137},
  urldate = {2023-04-04},
  abstract = {Our ability to plan and execute a series of tasks leading to a desired goal requires remarkable coordination between sensory, motor, and decision-related systems. Prefrontal cortex (PFC) is thought to play a central role in this coordination, especially when actions must be assembled extemporaneously and cannot be programmed as a rote series of movements. A central component of this flexible behavior is the moment-by-moment allocation of working memory and attention. The ubiquity of sequence planning in our everyday lives belies the neural complexity that supports this capacity, and little is known about how frontal cortical regions orchestrate the monitoring and control of sequential behaviors. For example, it remains unclear if and how sensory cortical areas, which provide essential driving inputs for behavior, are modulated by the frontal cortex during these tasks. Here, we review what is known about moment-to-moment monitoring as it relates to visually guided, rule-driven behaviors that change over time. We highlight recent human work that shows how the rostrolateral prefrontal cortex (RLPFC) participates in monitoring during task sequences. Neurophysiological data from monkeys suggests that monitoring may be accomplished by neurons that respond to items within the sequence and may in turn influence the tuning properties of neurons in posterior sensory areas. Understanding the interplay between proceduralized or habitual acts and supervised control of sequences is key to our understanding of sequential task execution. A crucial bridge will be the use of experimental protocols that allow for the examination of the functional homology between monkeys and humans. We illustrate how task sequences may be parceled into components and examined experimentally, thereby opening future avenues of investigation into the neural basis of sequential monitoring and control.},
  file = {/home/kelly/Zotero/storage/8MDCJR3A/Desrochers et al. - 2016 - The Monitoring and Control of Task Sequences in Hu.pdf}
}

@article{desrochersOptimalHabitsCan2010,
  title = {Optimal Habits Can Develop Spontaneously through Sensitivity to Local Cost},
  author = {Desrochers, Theresa M. and Jin, Dezhe Z. and Goodman, Noah D. and Graybiel, Ann M.},
  year = {2010},
  month = nov,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {107},
  number = {47},
  pages = {20512--20517},
  publisher = {{Proceedings of the National Academy of Sciences}},
  urldate = {2023-04-04},
  abstract = {Habits and rituals are expressed universally across animal species. These behaviors are advantageous in allowing sequential behaviors to be performed without cognitive overload, and appear to rely on neural circuits that are relatively benign but vulnerable to takeover by extreme contexts, neuropsychiatric sequelae, and processes leading to addiction. Reinforcement learning (RL) is thought to underlie the formation of optimal habits. However, this theoretic formulation has principally been tested experimentally in simple stimulus-response tasks with relatively few available responses. We asked whether RL could also account for the emergence of habitual action sequences in realistically complex situations in which no repetitive stimulus-response links were present and in which many response options were present. We exposed na\"ive macaque monkeys to such experimental conditions by introducing a unique free saccade scan task. Despite the highly uncertain conditions and no instruction, the monkeys developed a succession of stereotypical, self-chosen saccade sequence patterns. Remarkably, these continued to morph for months, long after session-averaged reward and cost (eye movement distance) reached asymptote. Prima facie, these continued behavioral changes appeared to challenge RL. However, trial-by-trial analysis showed that pattern changes on adjacent trials were predicted by lowered cost, and RL simulations that reduced the cost reproduced the monkeys' behavior. Ultimately, the patterns settled into stereotypical saccade sequences that minimized the cost of obtaining the reward on average. These findings suggest that brain mechanisms underlying the emergence of habits, and perhaps unwanted repetitive behaviors in clinical disorders, could follow RL algorithms capturing extremely local explore/exploit tradeoffs.},
  file = {/home/kelly/Zotero/storage/VSL4RREV/Desrochers et al. - 2010 - Optimal habits can develop spontaneously through s.pdf}
}

@article{dezfouliHabitsActionSequences2012,
  title = {Habits, Action Sequences and Reinforcement Learning},
  author = {Dezfouli, Amir and Balleine, Bernard W.},
  year = {2012},
  journal = {European Journal of Neuroscience},
  volume = {35},
  number = {7},
  pages = {1036--1051},
  issn = {1460-9568},
  urldate = {2023-07-04},
  abstract = {It is now widely accepted that instrumental actions can be either goal-directed or habitual; whereas the former are rapidly acquired and regulated by their outcome, the latter are reflexive, elicited by antecedent stimuli rather than their consequences. Model-based reinforcement learning (RL) provides an elegant description of goal-directed action. Through exposure to states, actions and rewards, the agent rapidly constructs a model of the world and can choose an appropriate action based on quite abstract changes in environmental and evaluative demands. This model is powerful but has a problem explaining the development of habitual actions. To account for habits, theorists have argued that another action controller is required, called model-free RL, that does not form a model of the world but rather caches action values within states allowing a state to select an action based on its reward history rather than its consequences. Nevertheless, there are persistent problems with important predictions from the model; most notably the failure of model-free RL correctly to predict the insensitivity of habitual actions to changes in the action\textendash reward contingency. Here, we suggest that introducing model-free RL in instrumental conditioning is unnecessary, and demonstrate that reconceptualizing habits as action sequences allows model-based RL to be applied to both goal-directed and habitual actions in a manner consistent with what real animals do. This approach has significant implications for the way habits are currently investigated and generates new experimental predictions.},
  copyright = {\textcopyright{} 2012 The Authors. European Journal of Neuroscience \textcopyright{} 2012 Federation of European Neuroscience Societies and Blackwell Publishing Ltd},
  langid = {english},
  keywords = {action sequence,goal-directed action,habitual action,reinforcement learning},
  file = {/home/kelly/Zotero/storage/GJ4CFAZ9/Dezfouli and Balleine - 2012 - Habits, action sequences and reinforcement learnin.pdf;/home/kelly/Zotero/storage/B8HYMDF7/j.1460-9568.2012.08050.html}
}

@article{dezfouliHabitsActionSequences2014,
  title = {Habits as Action Sequences: Hierarchical Action Control and Changes in Outcome Value},
  shorttitle = {Habits as Action Sequences},
  author = {Dezfouli, Amir and Lingawi, Nura W. and Balleine, Bernard W.},
  year = {2014},
  month = nov,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {369},
  number = {1655},
  pages = {20130482},
  publisher = {{Royal Society}},
  urldate = {2023-07-04},
  abstract = {Goal-directed action involves making high-level choices that are implemented using previously acquired action sequences to attain desired goals. Such a hierarchical schema is necessary for goal-directed actions to be scalable to real-life situations, but results in decision-making that is less flexible than when action sequences are unfolded and the decision-maker deliberates step-by-step over the outcome of each individual action. In particular, from this perspective, the offline revaluation of any outcomes that fall within action sequence boundaries will be invisible to the high-level planner resulting in decisions that are insensitive to such changes. Here, within the context of a two-stage decision-making task, we demonstrate that this property can explain the emergence of habits. Next, we show how this hierarchical account explains the insensitivity of over-trained actions to changes in outcome value. Finally, we provide new data that show that, under extended extinction conditions, habitual behaviour can revert to goal-directed control, presumably as a consequence of decomposing action sequences into single actions. This hierarchical view suggests that the development of action sequences and the insensitivity of actions to changes in outcome value are essentially two sides of the same coin, explaining why these two aspects of automatic behaviour involve a shared neural structure.},
  keywords = {decision-making,goal-directed actions,habits},
  file = {/home/kelly/Zotero/storage/IJJYQQ9A/Dezfouli et al. - 2014 - Habits as action sequences hierarchical action co.pdf}
}

@article{esserLDOPAModulatesActivity2021,
  title = {L-{{DOPA}} Modulates Activity in the {{vmPFC}}, Nucleus Accumbens, and {{VTA}} during Threat Extinction Learning in Humans},
  author = {Esser, Roland and Korn, Christoph W and Ganzer, Florian and Haaker, Jan},
  editor = {Shackman, Alexander and Frank, Michael J},
  year = {2021},
  month = sep,
  journal = {eLife},
  volume = {10},
  pages = {e65280},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  urldate = {2023-04-14},
  abstract = {Learning to be safe is central for adaptive behaviour when threats are no longer present. Detecting the absence of an expected threat is key for threat extinction learning and an essential process for the behavioural treatment of anxiety-related disorders. One possible mechanism underlying extinction learning is a dopaminergic mismatch signal that encodes the absence of an expected threat. Here we show that such a dopamine-related pathway underlies extinction learning in humans. Dopaminergic enhancement via administration of L-DOPA (vs. Placebo) was associated with reduced retention of differential psychophysiological threat responses at later test, which was mediated by activity in the ventromedial prefrontal cortex that was specific to extinction learning. L-DOPA administration enhanced signals at the time-point of an expected, but omitted threat in extinction learning within the nucleus accumbens, which were functionally coupled with the ventral tegmental area and the amygdala. Computational modelling of threat expectancies further revealed prediction error encoding in nucleus accumbens that was reduced when L-DOPA was administered. Our results thereby provide evidence that extinction learning is influenced by L-DOPA and provide a mechanistic perspective to augment extinction learning by dopaminergic enhancement in humans.},
  keywords = {amygdala,Dopamine,nucleus accumbens,vmPFC},
  file = {/home/kelly/Zotero/storage/YZJH7983/Esser et al. - 2021 - L-DOPA modulates activity in the vmPFC, nucleus ac.pdf}
}

@article{faureLesionNigrostriatalDopamine2005,
  title = {Lesion to the {{Nigrostriatal Dopamine System Disrupts Stimulus-Response Habit Formation}}},
  author = {Faure, Alexis and Haberland, Ulrike and Cond{\'e}, Fran{\c c}oise and Massioui, Nicole El},
  year = {2005},
  month = mar,
  journal = {Journal of Neuroscience},
  volume = {25},
  number = {11},
  pages = {2771--2780},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  urldate = {2022-07-12},
  abstract = {Acquisition and performance of instrumental actions are assumed to require both action-outcome and stimulus-response (S-R) habit processes. Over the course of extended training, control over instrumental performance shifts from goal-directed action-outcome associations to S-R associations that progressively gain domination over behavior. Lesions of the lateral part of the dorsal striatum disrupt this process, and rats with lesions to the lateral striatum showed selective sensitivity to devaluation of the instrumental outcome (Yin et al., 2004), indicating that this area is necessary for habit formation. The present experiment further explored the basis of this dysfunction by examining the ability of rats subjected to bilateral 6-hydroxydopamine lesions of the nigrostriatal dopaminergic pathway to develop behavioral autonomy with overtraining. Rats were given extended training on two cued instrumental tasks associating a stimulus (a tone or a light) with an instrumental action (lever press or chain pull) and a food reward (pellets or sucrose). Both tasks were run daily in separate sessions. Overtraining was followed by a test of goal sensitivity by satiety-specific devaluation of the reward. In control animals, one action (lever press) was insensitive to reward devaluation, indicating that it became a habit, whereas the second action (chain pull) was still sensitive to goal devaluation. This result provides evidence that the development of habit learning may depend on the characteristics of the response. In dopamine-depleted rats, lever press and chain pull remained sensitive to reward devaluation, evidencing a role of striatal dopamine transmission in habit formation.},
  chapter = {Behavioral/Systems/Cognitive},
  copyright = {Copyright \textcopyright{} 2005 Society for Neuroscience 0270-6474/05/252771-10.00/0},
  langid = {english},
  pmid = {15772337},
  keywords = {basal ganglia,dopamine,habit formation,instrumental learning,lateral striatum,substantia nigra},
  file = {/home/kelly/Zotero/storage/6MAX9MYJ/Faure et al. - 2005 - Lesion to the Nigrostriatal Dopamine System Disrup.pdf;/home/kelly/Zotero/storage/YKGRD8LE/2771.html}
}

@article{fitzgeraldDopamineRewardLearning2015,
  title = {Dopamine, Reward Learning, and Active Inference},
  author = {FitzGerald, Thomas H. B. and Dolan, Raymond J. and Friston, Karl},
  year = {2015},
  journal = {Frontiers in Computational Neuroscience},
  volume = {9},
  issn = {1662-5188},
  urldate = {2023-04-19},
  abstract = {Temporal difference learning models propose phasic dopamine signaling encodes reward prediction errors that drive learning. This is supported by studies where optogenetic stimulation of dopamine neurons can stand in lieu of actual reward. Nevertheless, a large body of data also shows that dopamine is not necessary for learning, and that dopamine depletion primarily affects task performance. We offer a resolution to this paradox based on an hypothesis that dopamine encodes the precision of beliefs about alternative actions, and thus controls the outcome-sensitivity of behavior. We extend an active inference scheme for solving Markov decision processes to include learning, and show that simulated dopamine dynamics strongly resemble those actually observed during instrumental conditioning. Furthermore, simulated dopamine depletion impairs performance but spares learning, while simulated excitation of dopamine neurons drives reward learning, through aberrant inference about outcome states. Our formal approach provides a novel and parsimonious reconciliation of apparently divergent experimental findings.},
  file = {/home/kelly/Zotero/storage/KJI4Y7DS/FitzGerald et al. - 2015 - Dopamine, reward learning, and active inference.pdf}
}

@article{foulshamEyeMovementsTheir2015,
  title = {Eye Movements and Their Functions in Everyday Tasks},
  author = {Foulsham, T.},
  year = {2015},
  month = feb,
  journal = {Eye},
  volume = {29},
  number = {2},
  pages = {196--199},
  publisher = {{Nature Publishing Group}},
  issn = {1476-5454},
  urldate = {2022-07-05},
  abstract = {Human saccades and fixations have numerous functions in complex everyday tasks, which have sometimes been neglected in simple experimental situations. In this review I describe some of the characteristics of eye movement behaviour during real-world interactions with objects, while walking in natural environments and while holding a conversation. When performing real-world actions and walking around the world, we fixate relevant features at critical time points during the task. The eye movements between these fixations are planned and coordinated alongside head and body movements, often occurring a short time before the corresponding action. In social interactions, eye movements are both a mechanism for taking in information (for example, when looking at someone's face or following their gaze) and for signalling one's attention to another person. Thus eye movements are specific to a particular task context and subject to high-level planning and control during everyday actions.},
  copyright = {2015 Royal College of Ophthalmologists},
  langid = {english},
  keywords = {Perception},
  file = {/home/kelly/Zotero/storage/M63W75W6/Foulsham - 2015 - Eye movements and their functions in everyday task.pdf;/home/kelly/Zotero/storage/26NG4JU7/eye2014275.html}
}

@article{fristonDopamineAffordanceActive2012,
  title = {Dopamine, {{Affordance}} and {{Active Inference}}},
  author = {Friston, Karl J. and Shiner, Tamara and FitzGerald, Thomas and Galea, Joseph M. and Adams, Rick and Brown, Harriet and Dolan, Raymond J. and Moran, Rosalyn and Stephan, Klaas Enno and Bestmann, Sven},
  year = {2012},
  month = jan,
  journal = {PLOS Computational Biology},
  volume = {8},
  number = {1},
  pages = {e1002327},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  urldate = {2023-04-14},
  abstract = {The role of dopamine in behaviour and decision-making is often cast in terms of reinforcement learning and optimal decision theory. Here, we present an alternative view that frames the physiology of dopamine in terms of Bayes-optimal behaviour. In this account, dopamine controls the precision or salience of (external or internal) cues that engender action. In other words, dopamine balances bottom-up sensory information and top-down prior beliefs when making hierarchical inferences (predictions) about cues that have affordance. In this paper, we focus on the consequences of changing tonic levels of dopamine firing using simulations of cued sequential movements. Crucially, the predictions driving movements are based upon a hierarchical generative model that infers the context in which movements are made. This means that we can confuse agents by changing the context (order) in which cues are presented. These simulations provide a (Bayes-optimal) model of contextual uncertainty and set switching that can be quantified in terms of behavioural and electrophysiological responses. Furthermore, one can simulate dopaminergic lesions (by changing the precision of prediction errors) to produce pathological behaviours that are reminiscent of those seen in neurological disorders such as Parkinson's disease. We use these simulations to demonstrate how a single functional role for dopamine at the synaptic level can manifest in different ways at the behavioural level.},
  langid = {english},
  keywords = {Behavior,Dopamine,Dopaminergics,Free energy,Learning,Reaction time,Sensory cues,Sensory perception},
  file = {/home/kelly/Zotero/storage/ZNK6UQGJ/Friston et al. - 2012 - Dopamine, Affordance and Active Inference.pdf}
}

@article{giommiFlexibleSelfPsychopathology2023,
  title = {The ({{In}})Flexible Self: {{Psychopathology}}, Mindfulness, and Neuroscience},
  shorttitle = {The ({{In}})Flexible Self},
  author = {Giommi, Fabio and Bauer, Prisca R. and {Berkovich-Ohana}, Aviva and Barendregt, Henk and Brown, Kirk Warren and Gallagher, Shaun and Nykl{\'i}{\v c}ek, Ivan and Ostafin, Brian and Raffone, Antonino and Slagter, Heleen A. and Trautwein, Fynn-Mathis and Vago, David R.},
  year = {2023},
  month = oct,
  journal = {International Journal of Clinical and Health Psychology},
  volume = {23},
  number = {4},
  pages = {100381},
  issn = {1697-2600},
  urldate = {2023-06-07},
  abstract = {Clinical and neuroscientific evidence indicates that transdiagnostic processes contribute to the generation and maintenance of psychopathological symptoms and disorders. Rigidity (inflexibility) appears a core feature of most transdiagnostic pathological processes. Decreasing rigidity may prove important to restore and maintain mental health. One of the primary domains in which rigidity and flexibility plays a role concerns the self. We adopt the pattern theory of self (PTS) for a working definition of self. This incorporates the pluralist view on self as constituted by multiple aspects or processes, understood to constitute a self-pattern, i.e. processes organized in non-linear dynamical relations across a number of time scales. The use of mindfulness meditation in the format of Mindfulness Based Interventions (MBIs) has been developed over four decades in Clinical Psychology. MBIs are promising as evidence-based treatments, shown to be equivalent to gold-standard treatments and superior to specific active controls in several randomized controlled trials. Notably, MBIs have been shown to target transdiagnostic symptoms. Given the hypothesized central role of rigid, habitual self-patterns in psychopathology, PTS offers a useful frame to understand how mindfulness may be beneficial in decreasing inflexibility. We discuss the evidence that mindfulness can alter the psychological and behavioral expression of individual aspects of the self-pattern, as well as favour change in the self-pattern as a whole gestalt. We discuss neuroscientific research on how the phenomenology of the self (pattern) is reflected in associated cortical networks and meditation-related alterations in cortical networks. Creating a synergy between these two aspects can increase understanding of psychopathological processes and improve diagnostic and therapeutic options.},
  langid = {english},
  keywords = {Cognitive neuroscience,Neuroimaging,Pattern theory of self (PTS),Rigidity,Transdiagnostic processes},
  file = {/home/kelly/Zotero/storage/UG9KIGSL/Giommi et al. - 2023 - The (In)flexible self Psychopathology, mindfulnes.pdf;/home/kelly/Zotero/storage/LFYTI6R9/S1697260023000170.html}
}

@article{goudarComparingRapidRulelearning2023,
  title = {Comparing Rapid Rule-Learning Strategies in Humans and Monkeys},
  author = {Goudar, V. and Kim, J.-W. and Liu, Y. and Dede, A.J.O. and Jutras, M.J. and Skelin, I. and Ruvalcaba, M. and Chang, W. and Fairhall, A.L. and Lin, J.J. and Knight, R.T. and Buffalo, E.A. and Wang, X.-J.},
  year = {2023},
  journal = {bioRxiv},
  issn = {2692-8205},
  abstract = {Inter-species comparisons are key to deriving an understanding of the behavioral and neural correlates of human cognition from animal models. We perform a detailed comparison of macaque monkey and human strategies on an analogue of the Wisconsin Card Sort Test, a widely studied and applied multi-attribute measure of cognitive function, wherein performance requires the inference of a changing rule given ambiguous feedback. We found that well-trained monkeys rapidly infer rules but are three times slower than humans. Model fits to their choices revealed hidden states akin to feature-based attention in both species, and decision processes that resembled a Win-stay lose-shift strategy with key differences. Monkeys and humans test multiple rule hypotheses over a series of rule-search trials and perform inference-like computations to exclude candidates. An attention-set based learning stage categorization revealed that perseveration, random exploration and poor sensitivity to negative feedback explain the under-performance in monkeys. The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under a CC-BY-ND 4.0 International license.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/9WF2VR7G/Goudar et al. - 2023 - Comparing rapid rule-learning strategies in humans.pdf;/home/kelly/Zotero/storage/6IRVU9LH/display.html}
}

@article{graybielStriatumWhereSkills2015,
  title = {The {{Striatum}}: {{Where Skills}} and {{Habits Meet}}},
  shorttitle = {The {{Striatum}}},
  author = {Graybiel, Ann M. and Grafton, Scott T.},
  year = {2015},
  month = jan,
  journal = {Cold Spring Harbor Perspectives in Biology},
  volume = {7},
  number = {8},
  pages = {a021691},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {, 1943-0264},
  urldate = {2023-07-04},
  abstract = {After more than a century of work concentrating on the motor functions of the basal ganglia, new ideas have emerged, suggesting that the basal ganglia also have major functions in relation to learning habits and acquiring motor skills. We review the evidence supporting the role of the striatum in optimizing behavior by refining action selection and in shaping habits and skills as a modulator of motor repertoires. These findings challenge the notion that striatal learning processes are limited to the motor domain. The learning mechanisms supported by striatal circuitry generalize to other domains, including cognitive skills and emotion-related patterns of action.},
  langid = {english},
  pmid = {26238359},
  file = {/home/kelly/Zotero/storage/H8HL56Z8/Graybiel and Grafton - 2015 - The Striatum Where Skills and Habits Meet.pdf}
}

@article{greenbergMindTrapMindfulness2012,
  title = {``{{Mind}} the {{Trap}}'': {{Mindfulness Practice Reduces Cognitive Rigidity}}},
  shorttitle = {``{{Mind}} the {{Trap}}''},
  author = {Greenberg, Jonathan and Reiner, Keren and Meiran, Nachshon},
  year = {2012},
  month = may,
  journal = {PLOS ONE},
  volume = {7},
  number = {5},
  pages = {e36206},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  urldate = {2023-06-12},
  abstract = {Two experiments examined the relation between mindfulness practice and cognitive rigidity by using a variation of the Einstellung water jar task. Participants were required to use three hypothetical jars to obtain a specific amount of water. Initial problems were solvable by the same complex formula, but in later problems (``critical'' or ``trap'' problems) solving was possible by an additional much simpler formula. A rigidity score was compiled through perseverance of the complex formula. In Experiment 1, experienced mindfulness meditators received significantly lower rigidity scores than non-meditators who had registered for their first meditation retreat. Similar results were obtained in randomized controlled Experiment 2 comparing non-meditators who underwent an eight meeting mindfulness program with a waiting list group. The authors conclude that mindfulness meditation reduces cognitive rigidity via the tendency to be ``blinded'' by experience. Results are discussed in light of the benefits of mindfulness practice regarding a reduced tendency to overlook novel and adaptive ways of responding due to past experience, both in and out of the clinical setting.},
  langid = {english},
  keywords = {ADHD,Attention,Computer software,Depression,Experimental psychology,Eyes,Psychometrics,Suicide},
  file = {/home/kelly/Zotero/storage/29MWKVHA/Greenberg et al. - 2012 - Mind the Trap Mindfulness Practice Reduces Cogn.pdf}
}

@article{harmerEnhancedAppetitiveConditioning1998,
  title = {Enhanced Appetitive Conditioning Following Repeated Pretreatment with D-Amphetamine},
  author = {Harmer, C. J. and Phillips, G. D.},
  year = {1998},
  journal = {Behavioural Pharmacology},
  volume = {9},
  number = {4},
  pages = {299--308},
  publisher = {{Lippincott Williams \& Wilkins}},
  address = {{US}},
  issn = {1473-5849},
  abstract = {Administered 2 mg/kg d-amphetamine or 1 ml/kg physiological saline to male rats once per day for 5 days to test the unconditioned approach-eliciting properties of the stimuli used. Training in a Pavlovian task began 6 days subsequently. In Stage 1, a stimulus (light or tone, S-) was presented negatively correlated with a source reward. In Stage 2, presentation of the alternative counterbalanced stimulus (S+) was paired with the availability of a 10\% sucrose solution. There were no differences between the 2 groups in their response to the S- stimulus. Sensitized Ss showed a selective enhancement in the acquisition of conditioned responding to S+, relative to vehicle-injected controls. No differences in behavior were seen during the prestimulus periods, nor during presentation of sucrose. The conditioned instrumental efficacy of S+, relative to S- was assessed in Stage 3, in which stimulus availability was contingent on a novel lever-press response. Both groups showed a similar preference for the S+ over the S- stimulus. Hence, Ss sensitized by prior d-amphetamine showed enhanced appetitive Pavlovian conditioning, without subsequent effect on conditioned reward efficacy. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Classical Conditioning,Dextroamphetamine,Dopamine,Nucleus Accumbens,Rats},
  file = {/home/kelly/Zotero/storage/4P4AN2M9/1998-12061-001.html}
}

@article{harrisContextualCueingImproves2017,
  title = {Contextual Cueing Improves Attentional Guidance, Even When Guidance Is Supposedly Optimal},
  author = {Harris, Anthony M. and Remington, Roger W.},
  year = {2017},
  month = may,
  journal = {Journal of Experimental Psychology. Human Perception and Performance},
  volume = {43},
  number = {5},
  pages = {926--940},
  issn = {1939-1277},
  abstract = {Visual search through previously encountered contexts typically produces reduced reaction times compared with search through novel contexts. This contextual cueing benefit is well established, but there is debate regarding its underlying mechanisms. Eye-tracking studies have consistently shown reduced number of fixations with repetition, supporting improvements in attentional guidance as the source of contextual cueing. However, contextual cueing benefits have been shown in conditions in which attentional guidance should already be optimal-namely, when attention is captured to the target location by an abrupt onset, or under pop-out conditions. These results have been used to argue for a response-related account of contextual cueing. Here, we combine eye tracking with response time to examine the mechanisms behind contextual cueing in spatially cued and pop-out conditions. Three experiments find consistent response time benefits with repetition, which appear to be driven almost entirely by a reduction in number of fixations, supporting improved attentional guidance as the mechanism behind contextual cueing. No differences were observed in the time between fixating the target and responding-our proxy for response related processes. Furthermore, the correlation between contextual cueing magnitude and the reduction in number of fixations on repeated contexts approaches 1. These results argue strongly that attentional guidance is facilitated by familiar search contexts, even when guidance is near-optimal. (PsycINFO Database Record},
  langid = {english},
  pmid = {28230395},
  keywords = {Adult,Attention,Cues,Eye Movement Measurements,Eye Movements,Female,Humans,Male,{Pattern Recognition, Visual},Psychomotor Performance,Reaction Time,Space Perception,Young Adult},
  file = {/home/kelly/Zotero/storage/ECPTZIBQ/Harris and Remington - 2017 - Contextual cueing improves attentional guidance, e.pdf}
}

@article{healdComputationalNeuralBases2023,
  title = {The {{Computational}} and {{Neural Bases}} of {{Context-Dependent Learning}}},
  author = {Heald, James B. and Wolpert, Daniel M. and Lengyel, M{\'a}t{\'e}},
  year = {2023},
  month = mar,
  journal = {Annual Review of Neuroscience},
  issn = {1545-4126},
  abstract = {Flexible behavior requires the creation, updating, and expression of memories to depend on context. While the neural underpinnings of each of these processes have been intensively studied, recent advances in computational modeling revealed a key challenge in context-dependent learning that had been largely ignored previously: Under naturalistic conditions, context is typically uncertain, necessitating contextual inference. We review a theoretical approach to formalizing context-dependent learning in the face of contextual uncertainty and the core computations it requires. We show how this approach begins to organize a large body of disparate experimental observations, from multiple levels of brain organization (including cells, circuits, systems, and behavior) and multiple brain regions (most prominently the prefrontal cortex, the hippocampus, and motor cortices), into a coherent framework. We argue that contextual inference may also be key to understanding continual learning in the brain. This theory-driven perspective places contextual inference as a core component of learning. Expected final online publication date for the Annual Review of Neuroscience, Volume 46 is July 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
  langid = {english},
  pmid = {36972611},
  file = {/home/kelly/Zotero/storage/GV8EXPR2/Heald et al. - 2023 - The Computational and Neural Bases of Context-Depe.pdf}
}

@article{hollermanDopamineNeuronsReport1998,
  title = {Dopamine Neurons Report an Error in the Temporal Prediction of Reward during Learning},
  author = {Hollerman, Jeffrey R. and Schultz, Wolfram},
  year = {1998},
  month = aug,
  journal = {Nature Neuroscience},
  volume = {1},
  number = {4},
  pages = {304--309},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  urldate = {2023-07-04},
  abstract = {Many behaviors are affected by rewards, undergoing long-term changes when rewards are different than predicted but remaining unchanged when rewards occur exactly as predicted. The discrepancy between reward occurrence and reward prediction is termed an 'error in reward prediction'. Dopamine neurons in the substantia nigra and the ventral tegmental area are believed to be involved in reward-dependent behaviors. Consistent with this role, they are activated by rewards, and because they are activated more strongly by unpredicted than by predicted rewards they may play a role in learning. The present study investigated whether monkey dopamine neurons code an error in reward prediction during the course of learning. Dopamine neuron responses reflected the changes in reward prediction during individual learning episodes; dopamine neurons were activated by rewards during early trials, when errors were frequent and rewards unpredictable, but activation was progressively reduced as performance was consolidated and rewards became more predictable. These neurons were also activated when rewards occurred at unpredicted times and were depressed when rewards were omitted at the predicted times. Thus, dopamine neurons code errors in the prediction of both the occurrence and the time of rewards. In this respect, their responses resemble the teaching signals that have been employed in particularly efficient computational learning models.},
  copyright = {1998 Nature America Inc.},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {/home/kelly/Zotero/storage/TQHEX8EB/Hollerman and Schultz - 1998 - Dopamine neurons report an error in the temporal p.pdf}
}

@article{humphriesDopaminergicControlExplorationExploitation2012,
  title = {Dopaminergic {{Control}} of the {{Exploration-Exploitation Trade-Off}} via the {{Basal Ganglia}}},
  author = {Humphries, Mark D. and Khamassi, Mehdi and Gurney, Kevin},
  year = {2012},
  month = feb,
  journal = {Frontiers in Neuroscience},
  volume = {6},
  pages = {9},
  issn = {1662-4548},
  urldate = {2023-06-28},
  abstract = {We continuously face the dilemma of choosing between actions that gather new information or actions that exploit existing knowledge. This ``exploration-exploitation'' trade-off depends on the environment: stability favors exploiting knowledge to maximize gains; volatility favors exploring new options and discovering new outcomes. Here we set out to reconcile recent evidence for dopamine's involvement in the exploration-exploitation trade-off with the existing evidence for basal ganglia control of action selection, by testing the hypothesis that tonic dopamine in the striatum, the basal ganglia's input nucleus, sets the current exploration-exploitation trade-off. We first advance the idea of interpreting the basal ganglia output as a probability distribution function for action selection. Using computational models of the full basal ganglia circuit, we showed that, under this interpretation, the actions of dopamine within the striatum change the basal ganglia's output to favor the level of exploration or exploitation encoded in the probability distribution. We also found that our models predict striatal dopamine controls the exploration-exploitation trade-off if we instead read-out the probability distribution from the target nuclei of the basal ganglia, where their inhibitory input shapes the cortical input to these nuclei. Finally, by integrating the basal ganglia within a reinforcement learning model, we showed how dopamine's effect on the exploration-exploitation trade-off could be measurable in a forced two-choice task. These simulations also showed how tonic dopamine can appear to affect learning while only directly altering the trade-off. Thus, our models support the hypothesis that changes in tonic dopamine within the striatum can alter the exploration-exploitation trade-off by modulating the output of the basal ganglia.},
  pmcid = {PMC3272648},
  pmid = {22347155},
  file = {/home/kelly/Zotero/storage/L5QFPJUQ/Humphries et al. - 2012 - Dopaminergic Control of the Exploration-Exploitati.pdf}
}

@article{ikemotoRoleNucleusAccumbens1999,
  title = {The Role of Nucleus Accumbens Dopamine in Motivated Behavior: A Unifying Interpretation with Special Reference to Reward-Seeking},
  shorttitle = {The Role of Nucleus Accumbens Dopamine in Motivated Behavior},
  author = {Ikemoto, S. and Panksepp, J.},
  year = {1999},
  month = dec,
  journal = {Brain Research. Brain Research Reviews},
  volume = {31},
  number = {1},
  pages = {6--41},
  abstract = {Studies addressing behavioral functions of dopamine (DA) in the nucleus accumbens septi (NAS) are reviewed. A role of NAS DA in reward has long been suggested. However, some investigators have questioned the role of NAS DA in rewarding effects because of its role in aversive contexts. As findings supporting the role of NAS DA in mediating aversively motivated behaviors accumulate, it is necessary to accommodate such data for understanding the role of NAS DA in behavior. The aim of the present paper is to provide a unifying interpretation that can account for the functions of NAS DA in a variety of behavioral contexts: (1) its role in appetitive behavioral arousal, (2) its role as a facilitator as well as an inducer of reward processes, and (3) its presently undefined role in aversive contexts. The present analysis suggests that NAS DA plays an important role in sensorimotor integrations that facilitate flexible approach responses. Flexible approach responses are contrasted with fixed instrumental approach responses (habits), which may involve the nigro-striatal DA system more than the meso-accumbens DA system. Functional properties of NAS DA transmission are considered in two stages: unconditioned behavioral invigoration effects and incentive learning effects. (1) When organisms are presented with salient stimuli (e.g., novel stimuli and incentive stimuli), NAS DA is released and invigorates flexible approach responses (invigoration effects). (2) When proximal exteroceptive receptors are stimulated by unconditioned stimuli, NAS DA is released and enables stimulus representations to acquire incentive properties within specific environmental context. It is important to make a distinction that NAS DA is a critical component for the conditional formation of incentive representations but not the retrieval of incentive stimuli or behavioral expressions based on over-learned incentive responses (i.e., habits). Nor is NAS DA essential for the cognitive perception of environmental stimuli. Therefore, even without normal NAS DA transmission, the habit response system still allows animals to perform instrumental responses given that the tasks take place in fixed environment. Such a role of NAS DA as an incentive-property constructor is not limited to appetitive contexts but also aversive contexts. This dual action of NAS DA in invigoration and incentive learning may explain the rewarding effects of NAS DA as well as other effects of NAS DA in a variety of contexts including avoidance and unconditioned/conditioned increases in open-field locomotor activity. Particularly, the present hypothesis offers the following interpretation for the finding that both conditioned and unconditioned aversive stimuli stimulate DA release in the NAS: NAS DA invigorates approach responses toward 'safety'. Moreover, NAS DA modulates incentive properties of the environment so that organisms emit approach responses toward 'safety' (i.e., avoidance responses) when animals later encounter similar environmental contexts. There may be no obligatory relationship between NAS DA release and positive subjective effects, even though these systems probably interact with other brain systems which can mediate such effects. The present conceptual framework may be valuable in understanding the dynamic interplay of NAS DA neurochemistry and behavior, both normal and pathophysiological.},
  langid = {english},
  pmid = {10611493},
  keywords = {Animals,Behavior,{Behavior, Animal},Dopamine,Humans,Motivation,Nucleus Accumbens,Rats,Reward}
}

@article{jaiswalBetterCognitivePerformance2018,
  title = {Better {{Cognitive Performance Is Associated With}} the {{Combination}} of {{High Trait Mindfulness}} and {{Low Trait Anxiety}}},
  author = {Jaiswal, Satish and Tsai, Shao-Yang and Juan, Chi-Hung and Liang, Wei-Kuang and Muggleton, Neil G.},
  year = {2018},
  journal = {Frontiers in Psychology},
  volume = {9},
  issn = {1664-1078},
  urldate = {2023-06-02},
  abstract = {There are several ways in which cognitive and neurophysiological parameters have been consistently used to explain the variability in cognitive ability between people. However, little has been done to explore how such cognitive abilities are influenced by differences in personality traits. Dispositional mindfulness and anxiety are two inversely linked traits that have been independently attributed to a range of cognitive functions. The current study investigated these two traits in combination along with measures of the attentional network, cognitive inhibition, and visual working memory (VWM) capacity. A total of 392 prospective participants were screened to select two experimental groups each of 30 healthy young adults, with one having high mindfulness and low anxiety (HMLA) and the second having low mindfulness and high anxiety (LMHA). The groups performed an attentional network task, a color Stroop task, and a change detection test of VWM capacity. Results showed that the HMLA group was more accurate than the LMHA group on the Stroop and change detection tasks. Additionally, the HMLA group was more sensitive in detecting changes and had a higher WMC than the LMHA group. This research adds to the literature that has investigated mindfulness and anxiety independently with a comprehensive investigation of the effects of these two traits in conjunction on executive function.},
  file = {/home/kelly/Zotero/storage/Y9RH95PS/Jaiswal et al. - 2018 - Better Cognitive Performance Is Associated With th.pdf}
}

@article{janssenGreaterMindfulEating2018,
  title = {Greater Mindful Eating Practice Is Associated with Better Reversal Learning},
  author = {Janssen, Lieneke K. and Duif, Iris and {van Loon}, Ilke and {de Vries}, Jeanne H. M. and Speckens, Anne E. M. and Cools, Roshan and Aarts, Esther},
  year = {2018},
  month = apr,
  journal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {5702},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  urldate = {2023-04-18},
  abstract = {Mindfulness-based interventions are thought to reduce compulsive behavior such as overeating by promoting behavioral flexibility. Here the main aim was to provide support for mindfulness-mediated improvements in reversal learning, a direct measure of behavioral flexibility. We investigated whether an 8-week mindful eating intervention improved outcome-based reversal learning relative to an educational cooking (i.e., active control) intervention in a non-clinical population. Sixty-five healthy participants with a wide BMI range (19\textendash 35 kg/m2), who were motivated to change their eating habits, performed a deterministic reversal learning task that enabled the investigation of reward- and punishment-based reversal learning at baseline and following the intervention. No group differences in reversal learning were observed. However, time invested in the mindful eating, but not the educational cooking intervention correlated positively with changes in reversal learning, in a manner independent of outcome valence. These findings suggest that greater amount of mindfulness practice can lead to increased behavioral flexibility, which, in turn, might help overcome compulsive eating in clinical populations.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Human behaviour,Reward},
  file = {/home/kelly/Zotero/storage/49KAV7B4/Janssen et al. - 2018 - Greater mindful eating practice is associated with.pdf}
}

@article{jhaDoesMindfulnessTraining2019,
  title = {Does Mindfulness Training Help Working Memory `Work' Better?},
  author = {Jha, Amishi P and Denkova, Ekaterina and Zanesco, Anthony P and Witkin, Joanna E and Rooks, Joshua and Rogers, Scott L},
  year = {2019},
  month = aug,
  journal = {Current Opinion in Psychology},
  series = {Mindfulness},
  volume = {28},
  pages = {273--278},
  issn = {2352-250X},
  urldate = {2023-06-02},
  abstract = {There has been a proliferation of mindfulness training (MT) programs offered across a multitude of settings, including military, business, sports, education, and medicine. As such, ascertaining training effectiveness and determining best practices for program delivery are of the utmost importance. MT is often introduced to promote an array of desired effects from better mood, better leadership and management skills, to improved workplace or academic performance. Despite the diversity of factors motivating adoption of MTs, it can be argued from a cognitive training perspective that there should be uniformity in the core cognitive processes strengthened via repeated and systematic engagement in MT exercises. Herein, we explore the hypothesis that MT promotes salutary changes in the brain's working memory (WM) system. We review prior research and highlight aspects of MT programs that may be critical for achieving beneficial WM effects. Further, we suggest that given the centrality of WM in core processes such as emotion regulation, problem solving, and learning, MT programs capable of achieving WM benefits may be best positioned to promote other desired outcomes (e.g. reductions in negative mood). For these reasons, we recommend that more studies include WM metrics in their evaluation of MT programs.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/GUYEEKDP/S2352250X18301398.html}
}

@article{joelActorcriticModelsBasal2002,
  title = {Actor-Critic Models of the Basal Ganglia: New Anatomical and Computational Perspectives},
  shorttitle = {Actor-Critic Models of the Basal Ganglia},
  author = {Joel, Daphna and Niv, Yael and Ruppin, Eytan},
  year = {2002},
  journal = {Neural Networks: The Official Journal of the International Neural Network Society},
  volume = {15},
  number = {4-6},
  pages = {535--547},
  issn = {0893-6080},
  abstract = {A large number of computational models of information processing in the basal ganglia have been developed in recent years. Prominent in these are actor-critic models of basal ganglia functioning, which build on the strong resemblance between dopamine neuron activity and the temporal difference prediction error signal in the critic, and between dopamine-dependent long-term synaptic plasticity in the striatum and learning guided by a prediction error signal in the actor. We selectively review several actor-critic models of the basal ganglia with an emphasis on two important aspects: the way in which models of the critic reproduce the temporal dynamics of dopamine firing, and the extent to which models of the actor take into account known basal ganglia anatomy and physiology. To complement the efforts to relate basal ganglia mechanisms to reinforcement learning (RL), we introduce an alternative approach to modeling a critic network, which uses Evolutionary Computation techniques to 'evolve' an optimal RL mechanism, and relate the evolved mechanism to the basic model of the critic. We conclude our discussion of models of the critic by a critical discussion of the anatomical plausibility of implementations of a critic in basal ganglia circuitry, and conclude that such implementations build on assumptions that are inconsistent with the known anatomy of the basal ganglia. We return to the actor component of the actor-critic model, which is usually modeled at the striatal level with very little detail. We describe an alternative model of the basal ganglia which takes into account several important, and previously neglected, anatomical and physiological characteristics of basal ganglia-thalamocortical connectivity and suggests that the basal ganglia performs reinforcement-biased dimensionality reduction of cortical inputs. We further suggest that since such selective encoding may bias the representation at the level of the frontal cortex towards the selection of rewarded plans and actions, the reinforcement-driven dimensionality reduction framework may serve as a basis for basal ganglia actor models. We conclude with a short discussion of the dual role of the dopamine signal in RL and in behavioral switching.},
  langid = {english},
  pmid = {12371510},
  keywords = {Animals,Basal Ganglia,Humans,Learning,{Models, Biological},Nerve Net},
  file = {/home/kelly/Zotero/storage/KGMQH6AE/Joel et al. - 2002 - Actor-critic models of the basal ganglia new anat.pdf}
}

@article{kayserDopamineLocusControl2015,
  title = {Dopamine, {{Locus}} of {{Control}}, and the {{Exploration-Exploitation Tradeoff}}},
  author = {Kayser, Andrew S. and Mitchell, Jennifer M. and Weinstein, Dawn and Frank, Michael J.},
  year = {2015},
  month = jan,
  journal = {Neuropsychopharmacology},
  volume = {40},
  number = {2},
  pages = {454--462},
  publisher = {{Nature Publishing Group}},
  issn = {1740-634X},
  urldate = {2023-06-28},
  abstract = {Whether to continue to exploit a source of reward, or to search for a new one of potentially greater value, is a fundamental and underconstrained decision. Recent computational studies of this exploration-exploitation tradeoff have found that variability in exploration across individuals is influenced by a functional polymorphism (Val158Met) in the catechol-O-methyltransferase (COMT) gene, whose protein product degrades synaptically released dopamine. However, these and other genotype\textendash phenotype associations have rarely been causally tested. To directly test this association and to evaluate additional behavioral characteristics, including perceived locus of control (LOC), here we used the COMT inhibitor tolcapone in a randomized, double-blind, counterbalanced, within-subject study of 66 subjects genotyped for the Val158Met allele to assess the hypothesis that reducing COMT enzymatic activity interacts with genotype to increase uncertainty-driven exploration. In keeping with our initial hypothesis, tolcapone led to an increase in exploratory, but not exploitative, behavior in Met/Met rather than Val/Val subjects. Independent of genotype, those subjects with a more external LOC also showed increases in uncertainty-driven exploration on tolcapone relative to placebo. However, we did not replicate our previous finding that Met/Met subjects show greater exploration at baseline. Together these findings support a model in which exploration is hypothesized to have a dopaminergic basis. Moreover, in keeping with findings in other behavioral and cognitive domains, the response to an increase in presumptively frontal dopamine is dependent upon baseline dopamine tone.},
  copyright = {2015 American College of Neuropsychopharmacology},
  langid = {english},
  keywords = {Behavioural genetics,Cognitive control,Cognitive neuroscience,Computational neuroscience,Human behaviour,Pharmacology,Schizophrenia},
  file = {/home/kelly/Zotero/storage/W8K6N2V6/Kayser et al. - 2015 - Dopamine, Locus of Control, and the Exploration-Ex.pdf}
}

@article{keePowerNowBrief2013,
  title = {The {{Power}} of {{Now}}: {{Brief Mindfulness Induction Led}} to {{Increased Randomness}} of {{Clicking Sequence}}},
  shorttitle = {The {{Power}} of {{Now}}},
  author = {Kee, Ying Hwa and Chaturvedi, Iti and Wang, Chee Keng John and Chen, Lung Hung},
  year = {2013},
  month = jul,
  journal = {Motor Control},
  volume = {17},
  number = {3},
  pages = {238--255},
  publisher = {{Human Kinetics, Inc.}},
  issn = {1087-1640, 1543-2696},
  urldate = {2023-06-12},
  abstract = {The capacity for random movement production is known to be limited in humans (e.g., Newell, Deutsch, \& Morrison, 2000). We examined the effects of a brief mindfulness induction on random movement production because there are useful implications for variability in solving movement-related problems. The main task involved randomly clicking the 9 boxes in a 3 \texttimes{} 3 grid presented on a computer screen for five minutes. We characterized the sequence of clicking in terms of degrees of randomness, or periodicity, based on the fit, or probability, of the experimental data with its best fitting Bayesian network (4-click memory nodes) using the Markov chain Monte Carlo (MCMC) approach. Sixty-three participants were randomly assigned to either the experimental or the control condition. Mixed design repeated-measures ANOVA results show that the short mindfulness induction had a positive effect on the randomness of the sequence subsequently produced. This finding suggests that mindfulness may be a suitable strategy for increasing random movement behavior.},
  chapter = {Motor Control},
  langid = {american}
}

@article{kirkMindfulnessMeditationModulates2015,
  title = {Mindfulness Meditation Modulates Reward Prediction Errors in a Passive Conditioning Task},
  author = {Kirk, Ulrich and Montague, P. Read},
  year = {2015},
  journal = {Frontiers in Psychology},
  volume = {6},
  issn = {1664-1078},
  urldate = {2023-06-12},
  abstract = {Reinforcement learning models have demonstrated that phasic activity of dopamine neurons during reward expectation encodes information about the predictability of reward and cues that predict reward. Self-control strategies such as those practiced in mindfulness-based approaches is claimed to reduce negative and positive reactions to stimuli suggesting the hypothesis that such training may influence basic reward processing. Using a passive conditioning task and fMRI in a group of experienced mindfulness meditators and age-matched controls, we tested the hypothesis that mindfulness meditation influence reward and reward prediction error (PE) signals. We found diminished positive and negative PE-related blood-oxygen level-dependent (BOLD) responses in the putamen in meditators compared with controls. In the meditator group this decrease in striatal BOLD responses to reward PE was paralleled by increased activity in posterior insula, a primary interoceptive region. Critically, responses in the putamen during early trials of the conditioning procedure (run 1) were elevated in both meditators and controls. Overall, these results provide evidence that experienced mindfulness meditators are able to attenuate reward prediction signals to valenced stimuli, which may be related to interoceptive processes encoded in the posterior insula.},
  file = {/home/kelly/Zotero/storage/E3C7HP4R/Kirk and Montague - 2015 - Mindfulness meditation modulates reward prediction.pdf}
}

@article{kirkMindfulnessTrainingModulates2014,
  title = {Mindfulness Training Modulates Value Signals in Ventromedial Prefrontal Cortex through Input from Insular Cortex},
  author = {Kirk, Ulrich and Gu, Xiaosi and Harvey, Ann H. and Fonagy, Peter and Montague, P. Read},
  year = {2014},
  month = oct,
  journal = {NeuroImage},
  volume = {100},
  pages = {254--262},
  issn = {1095-9572},
  abstract = {Neuroimaging research has demonstrated that ventromedial prefrontal cortex (vmPFC) encodes value signals that can be modulated by top-down cognitive input such as semantic knowledge, price incentives, and monetary favors suggesting that such biases may have an identified biological basis. It has been hypothesized that mindfulness training (MT) provides one path for gaining control over such top-down influences; yet, there have been no direct tests of this hypothesis. Here, we probe the behavioral and neural effects of MT on value signals in vmPFC in a randomized longitudinal design of 8 weeks of MT on an initially na\"ive subject cohort. The impact of this within-subject training was assessed using two paradigms: one that employed primary rewards (fruit juice) in a simple conditioning task and another that used a well-validated art-viewing paradigm to test bias of monetary favors on preference. We show that MT behaviorally censors the top-down bias of monetary favors through a measurable influence on value signals in vmPFC. MT also modulates value signals in vmPFC to primary reward delivery. Using a separate cohort of subjects we show that 8 weeks of active control training (ACT) generates the same behavioral impact also through an effect on signals in the vmPFC. Importantly, functional connectivity analyses show that value signals in vmPFC are coupled with bilateral posterior insula in the MT groups in both paradigms, but not in the ACT groups. These results suggest that MT integrates interoceptive input from insular cortex in the context of value computations of both primary and secondary rewards.},
  langid = {english},
  pmcid = {PMC4140407},
  pmid = {24956066},
  keywords = {Adult,Brain Mapping,Cerebral Cortex,Female,fMRI,Humans,Insular cortex,Interoception,Longitudinal design,Longitudinal Studies,Magnetic Resonance Imaging,Male,Mindfulness,Mindfulness training,Prefrontal Cortex,Reward,Valuation,vmPFC,Young Adult},
  file = {/home/kelly/Zotero/storage/TTHV9WFS/Kirk et al. - 2014 - Mindfulness training modulates value signals in ve.pdf}
}

@article{kirkShorttermMindfulnessPractice2019,
  title = {Short-Term Mindfulness Practice Attenuates Reward Prediction Errors Signals in the Brain},
  author = {Kirk, Ulrich and Pagnoni, Giuseppe and H{\'e}tu, S{\'e}bastien and Montague, Read},
  year = {2019},
  month = may,
  journal = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {6964},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  urldate = {2023-04-14},
  abstract = {Activity changes in dopaminergic neurons encode the ongoing discrepancy between expected and actual value of a stimulus, providing a teaching signal for a reward prediction process. Previous work comparing a cohort of long-term Zen meditators to controls demonstrated an attenuation of reward prediction signals to appetitive reward in the striatum. Using a cross-commodity design encompassing primary- and secondary-reward conditioning experiments, the present study asks the question of whether reward prediction signals are causally altered by mindfulness training in na\"ive subjects. Volunteers were randomly assigned to 8 weeks of mindfulness training (MT), active control training (CT), or a one-time mindfulness induction group (MI). We observed a decreased response to positive prediction errors in the putamen in the MT group compared to CT using both a primary and a secondary-reward experiment. Furthermore, the posterior insula showed greater activation to primary rewards, independently of their predictability, in the MT group, relative to CT and MI group. These results support the notion that increased attention to the present moment and its interoceptive features - a core component of mindfulness practice - may reduce predictability effects in reward processing, without dampening (in fact, enhancing) the response to the actual delivery of the stimulus.},
  copyright = {2019 The Author(s)},
  langid = {english},
  keywords = {Decision,Neuroscience},
  file = {/home/kelly/Zotero/storage/DAIXHLVW/Kirk et al. - 2019 - Short-term mindfulness practice attenuates reward .pdf}
}

@article{kroemerLDOPAReducesModelfree2019,
  title = {L-{{DOPA}} Reduces Model-Free Control of Behavior by Attenuating the Transfer of Value to Action},
  author = {Kroemer, Nils B. and Lee, Ying and Pooseh, Shakoor and Eppinger, Ben and Goschke, Thomas and Smolka, Michael N.},
  year = {2019},
  month = feb,
  journal = {NeuroImage},
  volume = {186},
  pages = {113--125},
  issn = {1053-8119},
  urldate = {2023-06-28},
  abstract = {Dopamine is a key neurotransmitter in action control. However, influential theories of dopamine function make conflicting predictions about the effect of boosting dopamine neurotransmission. Here, we tested if increases in dopamine tone by administration of L-DOPA upregulate reward learning as predicted by reinforcement learning theories, and if increases are specific for deliberative ``model-based'' control or reflexive ``model-free'' control. Alternatively, L-DOPA may impair learning as suggested by ``value'' or ``thrift'' theories of dopamine. To this end, we employed a two-stage Markov decision-task to investigate the effect of L-DOPA (randomized cross-over) on behavioral control while brain activation was measured using fMRI. L-DOPA led to attenuated model-free control of behavior as indicated by the reduced impact of reward on choice. Increased model-based control was only observed in participants with high working memory capacity. Furthermore, L-DOPA facilitated exploratory behavior, particularly after a stream of wins in the task. Correspondingly, in the brain, L-DOPA decreased the effect of reward at the outcome stage and when the next decision had to be made. Critically, reward-learning rates and prediction error signals were unaffected by L-DOPA, indicating that differences in behavior and brain response to reward were not driven by differences in learning. Taken together, our results suggest that L-DOPA reduces model-free control of behavior by attenuating the transfer of value to action. These findings provide support for the value and thrift accounts of dopamine and call for a refined integration of valuation and action signals in reinforcement learning models.},
  langid = {english},
  keywords = {Computational modeling,Dopamine,fMRI,Goal-directed behavior,Pharmacology,Reward},
  file = {/home/kelly/Zotero/storage/ILPTPKPQ/Kroemer et al. - 2019 - L-DOPA reduces model-free control of behavior by a.pdf;/home/kelly/Zotero/storage/AVUTQ3FB/S1053811918320561.html}
}

@article{kunimatsuCaudalPartPutamen2019,
  title = {The {{Caudal Part}} of {{Putamen Represents}} the {{Historical Object Value Information}}},
  author = {Kunimatsu, Jun and Maeda, Kazutaka and Hikosaka, Okihide},
  year = {2019},
  month = feb,
  journal = {Journal of Neuroscience},
  volume = {39},
  number = {9},
  pages = {1709--1719},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  urldate = {2023-04-19},
  abstract = {The basal ganglia, especially the circuits originating from the putamen, are essential for controlling normal body movements. Notably, the putamen receives inputs not only from motor cortical areas but also from multiple sensory cortices. However, how these sensory signals are processed in the putamen remains unclear. We recorded the activity of tentative medium spiny neurons in the caudal part of the putamen when the monkey viewed many fractal objects. We found many neurons that responded to these objects, mostly in the ventral region. We called this region ``putamen tail'' (PUTt), as it is dorsally adjacent to ``caudate tail'' (CDt). Although PUTt and CDt are mostly separated by a thin layer of white matter, their neurons shared several features. Almost all of them had receptive fields in the contralateral hemifield. Moreover, their responses were object selective (i.e., variable across objects). The object selectivity was higher in the ventral region (i.e., CDt {$>$} PUTt). Some neurons above PUTt, which we called the caudal\textendash dorsal putamen (cdPUT), also responded to objects, but less selectively than PUTt. Next, we examined whether these visual neurons changed their responses based on the reward outcome. We found that many neurons encoded the values of many objects based on long-term memory, but not based on short-term memory. Such stable value responses were stronger in PUTt and CDt than in cdPUT. These results suggest that PUTt, together with CDt, controls saccade/attention among objects with different historical values, and may control other motor actions as well. SIGNIFICANCE STATEMENT Although the putamen receives inputs not only from motor cortical areas but also from sensory cortical areas, how these sensory signals are processed remains unclear. Here we found that neurons in the caudal\textendash ventral part of the putamen (putamen tail) process visual information including spatial and object features. These neurons discriminate many objects, first by their visual features and later by their reward values as well. Importantly, the value discrimination was based on long-term memory, but not on short-term memory. These results suggest that the putamen tail controls saccade/attention among objects with different historical values and might control other motor actions as well.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2019 the authors 0270-6474/19/391709-11\$15.00/0},
  langid = {english},
  pmid = {30573645},
  keywords = {caudate nucleus,long-term memory,object value,putamen,rhesus monkey,single neurons},
  file = {/home/kelly/Zotero/storage/SH4MWJH5/Kunimatsu et al. - 2019 - The Caudal Part of Putamen Represents the Historic.pdf}
}

@article{kuoResetTaskSet2015,
  title = {Reset a Task Set after Five Minutes of Mindfulness Practice},
  author = {Kuo, Chun-Yu and Yeh, Yei-Yu},
  year = {2015},
  month = sep,
  journal = {Consciousness and Cognition},
  volume = {35},
  pages = {98--109},
  issn = {1053-8100},
  urldate = {2023-06-12},
  abstract = {This study aimed to evaluate the impact of a brief mindfulness practice on reducing the carryover effect caused by a previous task set and to determine the mechanism for its effectiveness. Experiment 1 showed that a memorized color interfered with subsequent visual search as a singleton distractor only when color was a defining feature for the search target. In Experiment 2, three interventions (scene-viewing, distraction, and mindfulness practice) were implemented across three groups for five minutes between two blocks; color was relevant to search in the first block and irrelevant in the second. Only the mindfulness group showed a non-significant carryover effect. Experiment 3 demonstrated that the scene-viewing participants continued adopting a suppressive mode of attentional control on a previously distracting color during letter judgment. In contrast, mindfulness practice could reset a task set. Mindfulness practice could enhance concentration in the present moment via reconfiguring the mode of attentional control.},
  langid = {english},
  keywords = {Attentional capture,Attentional control,Mindfulness,Task-set inertia},
  file = {/home/kelly/Zotero/storage/V2RY82H3/Kuo and Yeh - 2015 - Reset a task set after five minutes of mindfulness.pdf;/home/kelly/Zotero/storage/SELV933L/S1053810015001002.html}
}

@article{langeWeakEvidenceNeural2023,
  title = {Weak {{Evidence}} for {{Neural Correlates}} of {{Task-Switching}} in {{Macaque V1}}},
  author = {Lange, Richard D. and {Gomez-Laberge}, Camille and Berezovskii, Vladimir K. and Plenetev, Anton and Sherdil, Ariana and Hartmann, Till and Haefner, Ralf M. and Born, Richard T.},
  year = {2023},
  month = mar,
  journal = {Journal of Neurophysiology},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  urldate = {2023-03-26},
  abstract = {A central goal of systems neuroscience is to understand how populations of sensory neurons encode and relay information to the rest of the brain. Three key quantities of interest are (i) how mean neural activity depends on the stimulus (sensitivity), (ii) how neural activity (co)varies around the mean (noise correlations), and (iii) how predictive these variations are of the subject's behavior (choice probability). Previous empirical work suggests that both choice probability and noise correlations are affected by task training, with decision-related information fed back to sensory areas and aligned to neural sensitivity on a task-by-task basis. We used Utah arrays to record activity from populations of V1 neurons from two macaque monkeys who were trained to switch between two coarse orientation-discrimination tasks. Surprisingly, we find no evidence for significant trial-by-trial changes in noise covariance between tasks, nor do we find a consistent relationship between neural sensitivity and choice probability, despite recording from well-tuned task-sensitive neurons, many of which were histologically confirmed to be in supragranular V1, and despite behavioral evidence that the monkeys switched their strategy between tasks. Thus our data at best provide weak support for the hypothesis that trial-by-trial task-switching induces changes to noise correlations and choice probabilities in V1. However, our data agrees with a recent finding of a single "choice axis" across tasks. It also raises the intriguing possibility that choice-related signals in early sensory areas are less indicative of task learning per se, and instead reflect perceptual learning that occurs in highly over-trained subjects.},
  keywords = {choice probability,noise correlations,task switching,V1},
  file = {/home/kelly/Zotero/storage/MVM8RM42/Lange et al. - 2023 - Weak Evidence for Neural Correlates of Task-Switch.pdf}
}

@article{laukkonenManyOneMeditation2021,
  title = {From Many to (n)One: {{Meditation}} and the Plasticity of the Predictive Mind},
  shorttitle = {From Many to (n)One},
  author = {Laukkonen, Ruben E. and Slagter, Heleen A.},
  year = {2021},
  month = sep,
  journal = {Neuroscience \& Biobehavioral Reviews},
  volume = {128},
  pages = {199--217},
  issn = {0149-7634},
  urldate = {2023-04-14},
  abstract = {How profoundly can humans change their own minds? In this paper we offer a unifying account of deconstructive meditation under the predictive processing view. We start from simple axioms. First, the brain makes predictions based on past experience, both phylogenetic and ontogenetic. Second, deconstructive meditation brings one closer to the here and now by disengaging anticipatory processes. We propose that practicing meditation therefore gradually reduces counterfactual temporally deep cognition, until all conceptual processing falls away, unveiling a state of pure awareness. Our account also places three main styles of meditation (focused attention, open monitoring, and non-dual) on a single continuum, where each technique relinquishes increasingly engrained habits of prediction, including the predicted self. This deconstruction can also permit certain insights by making the above processes available to introspection. Our framework is consistent with the state of empirical and (neuro)phenomenological evidence and illuminates the top-down plasticity of the predictive mind. Experimental rigor, neurophenomenology, and no-report paradigms are needed to further understanding of how meditation affects predictive processing and the self.},
  langid = {english},
  keywords = {Attention,Brain,Consciousness,Insight,Meditation,Non-dual awareness,Plasticity,Predictive brain,Predictive processing,Sense of self},
  file = {/home/kelly/Zotero/storage/96J9WPP6/Laukkonen and Slagter - 2021 - From many to (n)one Meditation and the plasticity.pdf;/home/kelly/Zotero/storage/EI4JTJPV/S014976342100261X.html}
}

@article{leeInterferenceIntegrationHierarchical2022,
  title = {Interference and Integration in Hierarchical Task Learning},
  author = {Lee, Woo-Tek and Hazeltine, Eliot and Jiang, Jiefeng},
  year = {2022},
  month = jun,
  journal = {Journal of Experimental Psychology. General},
  issn = {1939-2222},
  abstract = {A key feature of human task learning is shared task representation: Simple, subordinate tasks can be learned and then shared by multiple complex superordinate tasks as building blocks to facilitate task learning. An important yet unanswered question is how superordinate tasks sharing the same subordinate task affects the learning and memory of each other. Leveraging theories of associative memory, we hypothesize that shared subordinate tasks can cause both interference and facilitation between superordinate tasks. These hypotheses are tested using a novel experimental task which trains participants to perform superordinate tasks consisting of shared, trained subordinate tasks. Across 3 experiments, we demonstrate that sharing a subordinate task can (a) impair the memory of previously learned superordinate tasks and (b) integrate learned superordinate tasks to facilitate new superordinate task learning without direct experience. These findings shed light on the organizational principles of task knowledge and their consequences on task learning. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
  langid = {english},
  pmid = {35737531}
}

@misc{leowDopamineIncreasesAccuracy2023,
  title = {Dopamine Increases Accuracy and Lengthens Deliberation Time in Explicit Motor Skill Learning},
  author = {Leow, Li-Ann and Bernheine, Lena and Carroll, Timothy J. and Dux, Paul E. and Filmer, Hannah L.},
  year = {2023},
  month = feb,
  primaryclass = {New Results},
  pages = {2023.01.31.526542},
  publisher = {{bioRxiv}},
  urldate = {2023-02-06},
  abstract = {Although animal research implicates a central role for dopamine in motor skill learning, a direct causal link has yet to be established in neurotypical humans. Here, we tested if a pharmacological manipulation of dopamine alters motor learning, using a paradigm which engaged explicit, goal-directed strategies. Participants (27 females, 11 males, aged 18-29 years) first consumed either 100mg of Levodopa (n=19), a dopamine precursor that increases dopamine availability, or placebo (n=19). Then, during training, participants learnt the explicit strategy of aiming away from presented targets by instructed angles of varying sizes. Targets shifted mid-movement by the instructed aiming angle. Task success was thus contingent upon aiming accuracy. The effect of the dopamine manipulations on skill learning was assessed during training, and at an overnight follow-up. Increasing dopamine availability improved aiming accuracy and lengthened reaction times, particularly for larger, more difficult aiming angles, both at training, and at follow-up. Results support the proposal that dopamine is important in decisions to engage instrumental motivation to optimise performance, particularly when learning to execute goal-directed strategies in motor skill learning.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {\textcopyright{} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {/home/kelly/Zotero/storage/CPMZ2WKS/Leow et al. - 2023 - Dopamine increases accuracy and lengthens delibera.pdf}
}

@misc{leowDopamineIncreasesAccuracy2023a,
  title = {Dopamine Increases Accuracy and Lengthens Deliberation Time in Explicit Motor Skill Learning},
  author = {Leow, Li-Ann and Bernheine, Lena and Carroll, Timothy J. and Dux, Paul E. and Filmer, Hannah L.},
  year = {2023},
  month = feb,
  primaryclass = {New Results},
  pages = {2023.01.31.526542},
  publisher = {{bioRxiv}},
  urldate = {2023-04-19},
  abstract = {Although animal research implicates a central role for dopamine in motor skill learning, a direct causal link has yet to be established in neurotypical humans. Here, we tested if a pharmacological manipulation of dopamine alters motor learning, using a paradigm which engaged explicit, goal-directed strategies. Participants (27 females, 11 males, aged 18-29 years) first consumed either 100mg of Levodopa (n=19), a dopamine precursor that increases dopamine availability, or placebo (n=19). Then, during training, participants learnt the explicit strategy of aiming away from presented targets by instructed angles of varying sizes. Targets shifted mid-movement by the instructed aiming angle. Task success was thus contingent upon aiming accuracy. The effect of the dopamine manipulations on skill learning was assessed during training, and at an overnight follow-up. Increasing dopamine availability improved aiming accuracy and lengthened reaction times, particularly for larger, more difficult aiming angles, both at training, and at follow-up. Results support the proposal that dopamine is important in decisions to engage instrumental motivation to optimise performance, particularly when learning to execute goal-directed strategies in motor skill learning.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {\textcopyright{} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {/home/kelly/Zotero/storage/79GYL5UB/Leow et al. - 2023 - Dopamine increases accuracy and lengthens delibera.pdf}
}

@article{lutzEpistemicPragmaticValue2019,
  title = {The Epistemic and Pragmatic Value of Non-Action: A Predictive Coding Perspective on Meditation},
  shorttitle = {The Epistemic and Pragmatic Value of Non-Action},
  author = {Lutz, Antoine and Mattout, J{\'e}r{\'e}mie and Pagnoni, Giuseppe},
  year = {2019},
  month = aug,
  journal = {Current Opinion in Psychology},
  series = {Mindfulness},
  volume = {28},
  pages = {166--171},
  issn = {2352-250X},
  urldate = {2022-07-08},
  abstract = {The surge of interest about mindfulness meditation is associated with a growing empirical evidence about its impact on the mind and body. Yet, despite promising phenomenological or psychological models of mindfulness, a general mechanistic understanding of meditation steeped in neuroscience is still lacking. In parallel, predictive processing approaches to the mind are rapidly developing in the cognitive sciences with an impressive explanatory power: processes apparently as diverse as perception, action, attention, and learning, can be seen as unfolding and being coherently orchestrated according to the single general mandate of free-energy minimization. Here, we briefly explore the possibility to supplement previous phenomenological models of focused attention meditation by formulating them in terms of active inference. We first argue that this perspective can account for how paying voluntary attention to the body in meditation helps settling the mind by downweighting habitual and automatic trajectories of (pre)motor and autonomic reactions, as well as the pull of distracting spontaneous thought at the same time. Secondly, we discuss a possible relationship between phenomenological notions such as opacity and de-reification, and the deployment of precision-weighting via the voluntary allocation of attention. We propose the adoption of this theoretical framework as a promising strategy for contemplative research. Explicit computational simulations and comparisons with experimental and phenomenological data will be critical to fully develop this approach.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/KIQKMQJ6/Lutz et al. - 2019 - The epistemic and pragmatic value of non-action a.pdf;/home/kelly/Zotero/storage/P986D2AX/S2352250X18302355.html}
}

@article{mclennanActionDopamineNeurones1967,
  title = {The Action of Dopamine on Neurones of the Caudate Nucleus},
  author = {McLennan, H. and York, D. H.},
  year = {1967},
  month = apr,
  journal = {The Journal of Physiology},
  volume = {189},
  number = {3},
  pages = {393-402.1},
  issn = {0022-3751},
  urldate = {2023-06-12},
  abstract = {1. Dopamine applied iontophoretically to neurones of the caudate nucleus of cats caused excitation of some (9\% of those encountered) and depression of others (60\%). Some cells have been found affected both by dopamine and by acetylcholine., 2. The effects of dopamine could be prevented by the previous iontophoretic administration of phenoxybenzamine, but not by dichloroisopropylnoradrenaline., 3. Responses evoked in caudate neurones by electrical stimulation of substantia nigra were depressed by dopamine. No evidence for enhancement of the effects of nigral stimulation through the application of dopamine were detected., 4. Stimulation of nucleus centromedianus thalami depressed firing of caudate neurones., 5. The hypothesis that dopamine may act as an inhibitory synaptic transmitter within the caudate is put forward.},
  pmcid = {PMC1396117},
  pmid = {4382718},
  file = {/home/kelly/Zotero/storage/BDWXQB8U/McLennan and York - 1967 - The action of dopamine on neurones of the caudate .pdf}
}

@article{mehtaImpairedSetshiftingDissociable2004,
  title = {Impaired Set-Shifting and Dissociable Effects on Tests of Spatial Working Memory Following the Dopamine {{D2}} Receptor Antagonist Sulpiride in Human Volunteers},
  author = {Mehta, Mitul A. and Manes, Facundo F. and Magnolfi, Gianna and Sahakian, Barbara J. and Robbins, Trevor W.},
  year = {2004},
  month = nov,
  journal = {Psychopharmacology},
  volume = {176},
  number = {3},
  pages = {331--342},
  issn = {1432-2072},
  urldate = {2023-04-19},
  abstract = {Dopamine (DA) D2 receptor antagonists have been shown to produce similar impairments to those seen in Parkinson's disease. These include working memory and set-shifting deficits. Theories of DA function have predicted that distraction or impaired switching may be important determinants of such deficits.},
  langid = {english},
  keywords = {Attention,D2 receptor,Dopamine,Set-shifting,Working memory},
  file = {/home/kelly/Zotero/storage/W9J3XHCC/Mehta et al. - 2004 - Impaired set-shifting and dissociable effects on t.pdf}
}

@article{montagueComputationalRolesDopamine2004,
  title = {Computational Roles for Dopamine in Behavioural Control},
  author = {Montague, P. Read and Hyman, Steven E. and Cohen, Jonathan D.},
  year = {2004},
  month = oct,
  journal = {Nature},
  volume = {431},
  number = {7010},
  pages = {760--767},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  urldate = {2023-04-14},
  abstract = {Neuromodulators such as dopamine have a central role in cognitive disorders. In the past decade, biological findings on dopamine function have been infused with concepts taken from computational theories of reinforcement learning. These more abstract approaches have now been applied to describe the biological algorithms at play in our brains when we form value judgements and make choices. The application of such quantitative models has opened up new fields, ripe for attack by young synthesizers and theoreticians.},
  copyright = {2004 Nature Publishing Group},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/home/kelly/Zotero/storage/JZFPI2HI/Montague et al. - 2004 - Computational roles for dopamine in behavioural co.pdf}
}

@article{nadelOptogeneticStimulationStriatal2021,
  title = {Optogenetic Stimulation of Striatal Patches Modifies Habit Formation and Inhibits Dopamine Release},
  author = {Nadel, J. A. and Pawelko, S. S. and Scott, J. R. and McLaughlin, R. and Fox, M. and Ghanem, M. and {van der Merwe}, R. and Hollon, N. G. and Ramsson, E. S. and Howard, C. D.},
  year = {2021},
  month = oct,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {19847},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  urldate = {2023-07-04},
  abstract = {Habits are inflexible behaviors that develop after extensive repetition, and overreliance on habits is a hallmark of many pathological states. The striatum is involved in the transition from flexible to inflexible responding, and interspersed throughout the striatum are patches, or striosomes, which make up\,\textasciitilde 15\% of the volume of the striatum relative to the surrounding matrix compartment. Previous studies have suggested that patches are necessary for normal habit formation, but it remains unknown exactly how patches contribute to habit formation and expression. Here, using optogenetics, we stimulated striatal patches in Sepw1-NP67 mice during variable interval training (VI60), which is used to establish habitual responding. We found that activation of patches at reward retrieval resulted in elevated responding during VI60 training by modifying the pattern of head entry and pressing. Further, this optogenetic manipulation reduced subsequent responding following reinforcer devaluation, suggesting modified habit formation. However, patch stimulation did not generally increase extinction rates during a subsequent extinction probe, but did result in a small `extinction burst', further suggesting goal-directed behavior. On the other hand, this manipulation had no effect in omission trials, where mice had to withhold responses to obtain rewards. Finally, we utilized fast-scan cyclic voltammetry to investigate how patch activation modifies evoked striatal dopamine release and found that optogenetic activation of patch projections to the substantia nigra pars compacta (SNc) is sufficient to suppress dopamine release in the dorsal striatum. Overall, this work provides novel insight into the role of the patch compartment in habit formation, and provides a potential mechanism for how patches modify habitual behavior by exerting control over dopamine signaling.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Motivation,Neural circuits,Neuroscience,Operant learning,Reward},
  file = {/home/kelly/Zotero/storage/8Q98YH8E/Nadel et al. - 2021 - Optogenetic stimulation of striatal patches modifi.pdf}
}

@article{nakamuraRoleDopaminePrimate2006,
  title = {Role of {{Dopamine}} in the {{Primate Caudate Nucleus}} in {{Reward Modulation}} of {{Saccades}}},
  author = {Nakamura, Kae and Hikosaka, Okihide},
  year = {2006},
  month = may,
  journal = {The Journal of Neuroscience},
  volume = {26},
  number = {20},
  pages = {5360--5369},
  issn = {0270-6474},
  urldate = {2023-04-19},
  abstract = {Expected reward impacts behavior and neuronal activity in brain areas involved in sensorimotor processes. However, where and how reward signals affect sensorimotor signals is unclear. Here, we show evidence that reward-dependent modulation of behavior depends on normal dopamine transmission in the striatum. Monkeys performed a visually guided saccade task in which expected reward gain was different depending on the position of the target. Saccadic reaction times were reliably shorter on large-reward trials than on small-reward trials. When position\textendash reward contingency was switched, the reaction time difference changed rapidly. Injecting dopamine D1 antagonist into the caudate significantly attenuated the reward-dependent saccadic reaction time changes. Conversely, injecting D2 antagonist into the same region enhanced the reward-dependent changes. These results suggest that reward-dependent changes in saccadic eye movements depend partly on dopaminergic modulation of neuronal activity in the caudate nucleus.},
  pmcid = {PMC6675290},
  pmid = {16707788},
  file = {/home/kelly/Zotero/storage/9W3DXZUX/Nakamura and Hikosaka - 2006 - Role of Dopamine in the Primate Caudate Nucleus in.pdf}
}

@article{nakamuraRoleDopaminePrimate2006a,
  title = {Role of Dopamine in the Primate Caudate Nucleus in Reward Modulation of Saccades},
  author = {Nakamura, Kae and Hikosaka, Okihide},
  year = {2006},
  month = may,
  journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  volume = {26},
  number = {20},
  pages = {5360--5369},
  issn = {1529-2401},
  abstract = {Expected reward impacts behavior and neuronal activity in brain areas involved in sensorimotor processes. However, where and how reward signals affect sensorimotor signals is unclear. Here, we show evidence that reward-dependent modulation of behavior depends on normal dopamine transmission in the striatum. Monkeys performed a visually guided saccade task in which expected reward gain was different depending on the position of the target. Saccadic reaction times were reliably shorter on large-reward trials than on small-reward trials. When position-reward contingency was switched, the reaction time difference changed rapidly. Injecting dopamine D1 antagonist into the caudate significantly attenuated the reward-dependent saccadic reaction time changes. Conversely, injecting D2 antagonist into the same region enhanced the reward-dependent changes. These results suggest that reward-dependent changes in saccadic eye movements depend partly on dopaminergic modulation of neuronal activity in the caudate nucleus.},
  langid = {english},
  pmcid = {PMC6675290},
  pmid = {16707788},
  keywords = {Animals,Caudate Nucleus,Dopamine,Dopamine Antagonists,Dopamine D2 Receptor Antagonists,Female,Macaca mulatta,Neural Pathways,Neurons,Reaction Time,{Receptors, Dopamine D1},{Receptors, Dopamine D2},Saccades,Synaptic Transmission},
  file = {/home/kelly/Zotero/storage/RDP74HNS/Nakamura and Hikosaka - 2006 - Role of dopamine in the primate caudate nucleus in.pdf}
}

@article{nandamMethylphenidateNotAtomoxetine2011a,
  title = {Methylphenidate {{But Not Atomoxetine}} or {{Citalopram Modulates Inhibitory Control}} and {{Response Time Variability}}},
  author = {Nandam, L. Sanjay and Hester, Robert and Wagner, Joe and Cummins, Tarrant D. R. and Garner, Kelly and Dean, Angela J. and Kim, Bung Nyun and Nathan, Pradeep J. and Mattingley, Jason B. and Bellgrove, Mark A.},
  year = {2011},
  month = may,
  journal = {Biological Psychiatry},
  series = {Genes, {{Autism}}, and {{Associated Phenotypes}}},
  volume = {69},
  number = {9},
  pages = {902--904},
  issn = {0006-3223},
  urldate = {2022-07-12},
  abstract = {Background Response inhibition is a prototypical executive function of considerable clinical relevance to psychiatry. Nevertheless, our understanding of its pharmacological modulation remains incomplete. Methods We used a randomized, double-blind, placebo-controlled, crossover design to examine the effect of an acute dose of methylphenidate (MPH) (30 mg), atomoxetine (ATM) (60 mg), citalopram (CIT) (30 mg), and placebo (PLAC) (dextrose) on the stop signal inhibition task in 24 healthy, right-handed men 18\textendash 35 years of age. Participants performed the task under each of the four drug conditions across four consecutive sessions. Results Methylphenidate led to a reduction in both response time variability and stop-signal reaction time (SSRT), indicating enhanced response inhibition compared with all other drug conditions. Crucially, the enhancement of response inhibition by MPH occurred without concomitant changes in overall response speed, arguing against a simple enhancement of processing speed. We found no significant differences between ATM and PLAC, CIT and PLAC, or ATM and CIT for either response time variability or SSRT. Conclusions An acute dose of MPH but not ATM or CIT was able to improve SSRT and reduce response time variability in nonclinical participants. Improvements in response inhibition and response variability might underlie the reported clinical benefits of MPH in disorders such as attention-deficit/hyperactivity disorder.},
  langid = {english},
  keywords = {Atomoxetine,citalopram,methylphenidate,response inhibition,stop signal,variability},
  file = {/home/kelly/Zotero/storage/2T4LYMHB/S0006322310012023.html}
}

@article{nelsonAmphetamineExposureEnhances2006,
  title = {Amphetamine Exposure Enhances Habit Formation},
  author = {Nelson, Andrew and Killcross, Simon},
  year = {2006},
  month = apr,
  journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  volume = {26},
  number = {14},
  pages = {3805--3812},
  issn = {1529-2401},
  abstract = {Performance of instrumental actions in rats is initially sensitive to postconditioning changes in reward value, but after more extended training, behavior comes to be controlled by stimulus-response (S-R) habits that are no longer goal directed. To examine whether sensitization of dopaminergic systems leads to a more rapid transition from action-outcome processes to S-R habits, we examined performance of amphetamine-sensitized rats in an instrumental devaluation task. Animals were either sensitized (7 d, 2 mg/kg/d) before training (experiment 1) or sensitized between training and testing (experiment 2). Rats were trained to press a lever for a reward (three sessions) and were then given a test of goal sensitivity by devaluation of the instrumental outcome before testing in extinction. Control animals showed selective sensitivity to devaluation of the instrumental outcome. However, amphetamine sensitization administered before training caused the animals' responding to persist despite the changed value of the reinforcer. This deficit resulted from an inability to use representations of the outcome to guide behavior, because a reacquisition test confirmed that all of the animals had acquired an aversion to the reinforcer. In experiment 2, post-training sensitization did not disrupt normal goal-directed behavior. These findings indicate that amphetamine sensitization leads to a rapid progression from goal-directed to habit-based responding but does not affect the performance of established goal-directed actions.},
  langid = {english},
  pmcid = {PMC6674135},
  pmid = {16597734},
  keywords = {Amphetamine,Animals,{Behavior, Animal},Dopamine,Dopamine Agents,Habits,{Habituation, Psychophysiologic},Male,Rats,{Reinforcement, Psychology}},
  file = {/home/kelly/Zotero/storage/4R2TI8TC/Nelson and Killcross - 2006 - Amphetamine exposure enhances habit formation.pdf}
}

@article{nivDopamineRamps2013,
  title = {Dopamine Ramps Up},
  author = {Niv, Yael},
  year = {2013},
  month = aug,
  journal = {Nature},
  volume = {500},
  number = {7464},
  pages = {533--535},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  urldate = {2023-04-14},
  abstract = {We thought we had figured out dopamine, a neuromodulator involved in everything from learning to addiction. But the finding that dopamine levels ramp up as rats navigate to a reward may overthrow current theories. See Letter  p.575},
  copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Animal behaviour,Neuroscience},
  file = {/home/kelly/Zotero/storage/VH6PYQZN/Niv - 2013 - Dopamine ramps up.pdf}
}

@article{nonomuraMonitoringUpdatingAction2018,
  title = {Monitoring and {{Updating}} of {{Action Selection}} for {{Goal-Directed Behavior}} through the {{Striatal Direct}} and {{Indirect Pathways}}},
  author = {Nonomura, Satoshi and Nishizawa, Kayo and Sakai, Yutaka and Kawaguchi, Yasuo and Kato, Shigeki and Uchigashima, Motokazu and Watanabe, Masahiko and Yamanaka, Ko and Enomoto, Kazuki and Chiken, Satomi and Sano, Hiromi and Soma, Shogo and Yoshida, Junichi and Samejima, Kazuyuki and Ogawa, Masaaki and Kobayashi, Kazuto and Nambu, Atsushi and Isomura, Yoshikazu and Kimura, Minoru},
  year = {2018},
  month = sep,
  journal = {Neuron},
  volume = {99},
  number = {6},
  pages = {1302-1314.e5},
  issn = {0896-6273},
  urldate = {2023-04-28},
  abstract = {The basal ganglia play key roles in adaptive behaviors guided by reward and punishment. However, despite accumulating knowledge, few studies have tested how heterogeneous signals in the basal ganglia are~organized and coordinated for goal-directed behavior. In this study, we investigated neuronal signals of the direct and indirect pathways of the basal ganglia as rats performed a lever push/pull task for a probabilistic reward. In the dorsomedial striatum, we found that optogenetically and electrophysiologically identified direct pathway neurons encoded reward outcomes, whereas indirect pathway neurons encoded no-reward outcome and next-action selection. Outcome coding occurred in association with the chosen action. In support of pathway-specific neuronal coding, light activation induced a bias on repeat selection of the same action in the direct pathway, but on switch selection in the indirect pathway. Our data reveal the mechanisms underlying monitoring and updating of action selection for goal-directed behavior through basal ganglia circuits.},
  langid = {english},
  keywords = {action selection,antidromic activation,basal ganglia,decision making,direct and indirect pathway,dorsomedial striatum,optogenetics,outcome,punishment,reward},
  file = {/home/kelly/Zotero/storage/PFKMNU5N/Nonomura et al. - 2018 - Monitoring and Updating of Action Selection for Go.pdf;/home/kelly/Zotero/storage/KDD3NZHF/S0896627318306755.html}
}

@article{pattonFactorStructureBarratt1995,
  title = {Factor Structure of the {{Barratt}} Impulsiveness Scale},
  author = {Patton, J. H. and Stanford, M. S. and Barratt, E. S.},
  year = {1995},
  month = nov,
  journal = {Journal of Clinical Psychology},
  volume = {51},
  number = {6},
  pages = {768--774},
  issn = {0021-9762},
  abstract = {The purpose of the present study was to revise the Barratt Impulsiveness Scale Version 10 (BIS-10), identify the factor structure of the items among normals, and compare their scores on the revised form (BIS-11) with psychiatric inpatients and prison inmates. The scale was administered to 412 college undergraduates, 248 psychiatric inpatients, and 73 male prison inmates. Exploratory principal components analysis of the items identified six primary factors and three second-order factors. The three second-order factors were labeled Attentional Impulsiveness, Motor Impulsiveness, and Nonplanning Impulsiveness. Two of the three second-order factors identified in the BIS-11 were consistent with those proposed by Barratt (1985), but no cognitive impulsiveness component was identified per se. The results of the present study suggest that the total score of the BIS-11 is an internally consistent measure of impulsiveness and has potential clinical utility for measuring impulsiveness among selected patient and inmate populations.},
  langid = {english},
  pmid = {8778124},
  keywords = {Analysis of Variance,Case-Control Studies,{Disruptive, Impulse Control, and Conduct Disorders},{Factor Analysis, Statistical},Female,Humans,Impulsive Behavior,Male,Mental Disorders,Personality Inventory,Prisoners,Psychometrics,Substance-Related Disorders}
}

@article{pessiglioneDopaminedependentPredictionErrors2006,
  title = {Dopamine-Dependent Prediction Errors Underpin Reward-Seeking Behaviour in Humans},
  author = {Pessiglione, Mathias and Seymour, Ben and Flandin, Guillaume and Dolan, Raymond J. and Frith, Chris D.},
  year = {2006},
  month = aug,
  journal = {Nature},
  volume = {442},
  number = {7106},
  pages = {1042--1045},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  urldate = {2023-06-28},
  abstract = {The brain messenger dopamine is traditionally known as the 'pleasure molecule', linked with our desire for food and sex, as well as drug and gambling addictions. The precise function of dopamine in humans has remained elusive, and theories have relied almost exclusively on animal experiments. Using brain imaging technology, Pessiglione et al. scanned healthy human volunteers as they gambled for money after taking drugs that interfere with dopamine signals. Volunteers with boosted dopamine became better gamblers than their dopamine-suppressed counterparts. When dopamine levels were either enhanced or reduced by drugs, the scans showed that both reward-related learning and associated striatal activity are modulated, confirming the critical role of dopamine in integrating reward information for generation future decisions.},
  copyright = {2006 Springer Nature Limited},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/home/kelly/Zotero/storage/G5IVHTSH/Pessiglione et al. - 2006 - Dopamine-dependent prediction errors underpin rewa.pdf}
}

@article{pineDopamineTimeImpulsivity2010,
  title = {Dopamine, {{Time}}, and {{Impulsivity}} in {{Humans}}},
  author = {Pine, Alex and Shiner, Tamara and Seymour, Ben and Dolan, Raymond J.},
  year = {2010},
  month = jun,
  journal = {Journal of Neuroscience},
  volume = {30},
  number = {26},
  pages = {8888--8896},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  urldate = {2023-04-19},
  abstract = {Disordered dopamine neurotransmission is implicated in mediating impulsiveness across a range of behaviors and disorders including addiction, compulsive gambling, attention-deficit/hyperactivity disorder, and dopamine dysregulation syndrome. Whereas existing theories of dopamine function highlight mechanisms based on aberrant reward learning or behavioral disinhibition, they do not offer an adequate account of the pathological hypersensitivity to temporal delay that forms a crucial behavioral phenotype seen in these disorders. Here we provide evidence that a role for dopamine in controlling the relationship between the timing of future rewards and their subjective value can bridge this explanatory gap. Using an intertemporal choice task, we demonstrate that pharmacologically enhancing dopamine activity increases impulsivity by enhancing the diminutive influence of increasing delay on reward value (temporal discounting) and its corresponding neural representation in the striatum. This leads to a state of excessive discounting of temporally distant, relative to sooner, rewards. Thus our findings reveal a novel mechanism by which dopamine influences human decision-making that can account for behavioral aberrations associated with a hyperfunctioning dopamine system.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2010 the authors 0270-6474/10/308888-09\$15.00/0},
  langid = {english},
  pmid = {20592211},
  file = {/home/kelly/Zotero/storage/L2AUFLGH/Pine et al. - 2010 - Dopamine, Time, and Impulsivity in Humans.pdf}
}

@misc{rcoreteamLanguageEnvironmentStatistical2015,
  title = {R: {{A}} Language and Environment for Statistical  Computing.},
  author = {R Core Team},
  year = {2015},
  address = {{Vienna, Austria.}},
  howpublished = {R Foundation for Statistical Computing,}
}

@article{reedFocusedattentionMindfulnessIncreases2023,
  title = {Focused-Attention Mindfulness Increases Sensitivity to Current Schedules of Reinforcement},
  author = {Reed, Phil},
  year = {2023},
  journal = {Journal of Experimental Psychology: Animal Learning and Cognition},
  volume = {49},
  pages = {127--137},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {2329-8464},
  abstract = {Four experiments explored the impact of focused-attention mindfulness training on human performance on free-operant schedules of reinforcement. In each experiment, human participants responded on a multiple random ratio (RR), random interval (RI) schedule. In all experiments, responding was higher on RR than RI schedules, despite equated rates of reinforcement. A 10-min focused-attention mindfulness intervention (focused attention) produced greater differentiation between schedules than relaxation training (Experiments 1, 2, and 4), or no intervention (Experiment 3). Focused-attention mindfulness improved learning when the schedules associated with components of the multiple schedule were reversed. This occurred irrespective of whether the focused-attention mindfulness was before (Experiment 2) or after (Experiments 3 and 4) initial training, or whether compared to relaxation (Experiments 2 and 4) or no intervention (Experiment 3). In Experiment 4, following multiple RR, RI training, focused-attention mindfulness increased sensitivity to contingency reversal and did not interfere with previous training in a group that did not receive a contingency reversal. In contrast, relaxation training did not facilitate reversal learning and interfered with previous learning. The results suggest that focused-attention mindfulness improves awareness of operative contingencies by focusing participants on the present, rather than reducing interference from previous learning. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Awareness,Focused Attention,Learning,Mindfulness-Based Interventions,Reinforcement Schedules,Relaxation,Training},
  file = {/home/kelly/Zotero/storage/YBTZF7WJ/2023-65821-005.html}
}

@article{rentonNeurodeskAccessibleFlexible2022,
  title = {Neurodesk: {{An}} Accessible, Flexible, and Portable Data Analysis Environment for Reproducible Neuroimaging},
  shorttitle = {Neurodesk},
  author = {Renton, Angela I. and Dao, Thanh Thuy and Abbott, David F. and Bollmann, Saskia and Campbell, Megan EJ and Chang, Jeryn and Close, Thomas G. and Eckstein, Korbinian and Egan, Gary F. and Evas, Stefanie},
  year = {2022},
  journal = {bioRxiv},
  pages = {2022--12},
  publisher = {{Cold Spring Harbor Laboratory}}
}

@manual{rstudiocitation,
  type = {Manual},
  title = {{{RStudio}}: {{Integrated}} Development Environment for r},
  author = {{RStudio Team}},
  year = {2020},
  address = {{Boston, MA}},
  organization = {{RStudio, PBC.}}
}

@article{ruoccoDelineatingContributionsSustained2013,
  title = {Delineating the Contributions of Sustained Attention and Working Memory to Individual Differences in Mindfulness},
  author = {Ruocco, Anthony C. and Wonders, Elif},
  year = {2013},
  month = jan,
  journal = {Personality and Individual Differences},
  volume = {54},
  number = {2},
  pages = {226--230},
  issn = {0191-8869},
  urldate = {2023-06-02},
  abstract = {Mindfulness can be deconstructed into two constituent components: present-moment awareness and acceptance. Attention and working memory are theorized to contribute to individual differences in trait mindfulness, although the precise relationship among these constructs remains unclear. The purpose of the present study was to evaluate the association of neurocognitive indices of attention and working memory with a bidimensional trait measure of mindfulness. Fifty-five psychiatrically and neurologically healthy adults completed the Conners Continuous Performance Test, Penn Letter N-back Test, and Philadelphia Mindfulness Scale. Results indicated that present-moment awareness was associated with a response speed variability measure of sustained attention, whereas acceptance was more strongly linked to working memory efficiency, even after accounting for general intellectual ability. These findings suggest that sustained attention and working memory capacities may differentially subserve individual differences in present-moment awareness and acceptance, thereby illuminating our understanding of the cognitive mechanisms which may underlie trait mindfulness.},
  langid = {english},
  keywords = {Acceptance,Attention,Awareness,Mindfulness,Vigilance,Working memory},
  file = {/home/kelly/Zotero/storage/BEUL2YDU/S0191886912004278.html}
}

@article{rutledgeDopaminergicDrugsModulate2009,
  title = {Dopaminergic {{Drugs Modulate Learning Rates}} and {{Perseveration}} in {{Parkinson}}'s {{Patients}} in a {{Dynamic Foraging Task}}},
  author = {Rutledge, Robb B. and Lazzaro, Stephanie C. and Lau, Brian and Myers, Catherine E. and Gluck, Mark A. and Glimcher, Paul W.},
  year = {2009},
  month = dec,
  journal = {The Journal of Neuroscience},
  volume = {29},
  number = {48},
  pages = {15104--15114},
  issn = {0270-6474},
  urldate = {2023-04-14},
  abstract = {Making appropriate choices often requires the ability to learn the value of available options from experience. Parkinson's disease is characterized by a loss of dopamine neurons in the substantia nigra, neurons hypothesized to play a role in reinforcement learning. Although previous studies have shown that Parkinson's patients are impaired in tasks involving learning from feedback, they have not directly tested the widely held hypothesis that dopamine neuron activity specifically encodes the reward prediction error signal used in reinforcement learning models. To test a key prediction of this hypothesis, we fit choice behavior from a dynamic foraging task with reinforcement learning models and show that treatment with dopaminergic drugs alters choice behavior in a manner consistent with the theory. More specifically, we found that dopaminergic drugs selectively modulate learning from positive outcomes. We observed no effect of dopaminergic drugs on learning from negative outcomes. We also found a novel dopamine-dependent effect on decision making that is not accounted for by reinforcement learning models: perseveration in choice, independent of reward history, increases with Parkinson's disease and decreases with dopamine therapy.},
  pmcid = {PMC3376711},
  pmid = {19955362},
  file = {/home/kelly/Zotero/storage/KZ27SQVL/Rutledge et al. - 2009 - Dopaminergic Drugs Modulate Learning Rates and Per.pdf}
}

@article{salamoneMotivationalViewsReinforcement2002,
  title = {Motivational Views of Reinforcement: Implications for Understanding the Behavioral Functions of Nucleus Accumbens Dopamine},
  shorttitle = {Motivational Views of Reinforcement},
  author = {Salamone, John D. and Correa, Merc{\`e}},
  year = {2002},
  month = dec,
  journal = {Behavioural Brain Research},
  volume = {137},
  number = {1-2},
  pages = {3--25},
  issn = {0166-4328},
  abstract = {Although the Skinnerian 'Empirical Law of Effect' does not directly consider the fundamental properties of stimuli that enable them to act as reinforcers, such considerations are critical for determining if nucleus accumbens dopamine systems mediate reinforcement processes. Researchers who have attempted to identify the critical characteristics of reinforcing stimuli or activities have generally arrived at an emphasis upon motivational factors. A thorough review of the behavioral literature indicates that, across several different investigators offering a multitude of theoretical approaches, motivation is seen by many as being fundamental to the process of reinforcement. The reinforcer has been described as a goal, a commodity, an incentive, or a stimulus that is being approached, self-administered, attained or preserved. Reinforcers also have been described as activities that are preferred, deprived or in some way being regulated. It is evident that this 'motivational' or 'regulatory' view of reinforcement has had enormous influence over the hypothesis that DA directly mediates 'reward' or 'reinforcement' processes. Indeed, proponents of the DA/reward hypothesis regularly cite motivational theorists and employ their language. Nevertheless, considerable evidence indicates that low/moderate doses of DA antagonists, and depletions of DA in nucleus accumbens, can suppress instrumental responding for food while, at the same time, these conditions leave fundamental aspects of reinforcement (i.e. primary or unconditioned reinforcement; primary motivation or primary incentive properties of natural reinforcers) intact. Several complex features of the literature on dopaminergic involvement in reinforcement are examined below, and it is argued that the assertions that DA mediates 'reward' or 'reinforcement' are inaccurate and grossly oversimplified. Thus, it appears as though it is no longer tenable to assert that drugs of abuse are simply turning on the brain's natural 'reward system'. In relation to the hypothesis that DA systems are involved in 'wanting', but not 'liking', it is suggested in the present review that 'wanting' has both directional aspects (e.g. appetite to consume food) and activational aspects (e.g. activation for initiating and sustaining instrumental actions; tendency to work for food). The present paper reviews findings in support of the hypothesis that low doses of DA antagonists and accumbens DA depletions do not impair appetite to consume food, but do impair activational aspects of motivation. This suggestion is consistent with the studies showing that low doses of DA antagonists and accumbens DA depletions alter the relative allocation of instrumental responses, making the animals less likely to engage in instrumental responses that have a high degree of work-related response costs. In addition, this observation is consistent with studies demonstrating that accumbens DA depletions make rats highly sensitive to ratio requirements on operant schedules. Although accumbens DA is not seen as directly mediating appetite to consume food, principles of behavioral economics indicate that accumbens DA could be involved in the elasticity of demand for food in terms of the tendency to pay work-related response costs. Future research must focus upon how specific aspects of task requirements (i.e. ratio requirements, intermittence of reinforcement, temporal features of response requirements, dependence upon conditioned stimuli) interact with the effects of accumbens DA depletions, and which particular factors determine sensitivity to the effects of DA antagonism or depletion.},
  langid = {english},
  pmid = {12445713},
  keywords = {Animals,Appetite,{Conditioning, Operant},Corpus Striatum,Dopamine,Dopamine Agonists,Dopamine Antagonists,Motivation,Nucleus Accumbens,Rats,{Reinforcement, Psychology}}
}

@article{sandved-smithComputationalPhenomenologyMental2021,
  title = {Towards a Computational Phenomenology of Mental Action: Modelling Meta-Awareness and Attentional Control with Deep Parametric Active Inference},
  shorttitle = {Towards a Computational Phenomenology of Mental Action},
  author = {{Sandved-Smith}, Lars and Hesp, Casper and Mattout, J{\'e}r{\'e}mie and Friston, Karl and Lutz, Antoine and Ramstead, Maxwell J D},
  year = {2021},
  month = dec,
  journal = {Neuroscience of Consciousness},
  volume = {2021},
  number = {1},
  pages = {niab018},
  issn = {2057-2107},
  urldate = {2023-04-14},
  abstract = {Meta-awareness refers to the capacity to explicitly notice the current content of consciousness and has been identified as a key component for the successful control of cognitive states, such as the deliberate direction of attention. This paper proposes a formal model of meta-awareness and attentional control using hierarchical active inference. To do so, we cast mental action as policy selection over higher-level cognitive states and add a further hierarchical level to model meta-awareness states that modulate the expected confidence (precision) in the mapping between observations and hidden cognitive states. We simulate the example of mind-wandering and its regulation during a task involving sustained selective attention on a perceptual object. This provides a computational case study for an inferential architecture that is apt to enable the emergence of these central components of human phenomenology, namely, the ability to access and control cognitive states. We propose that this approach can be generalized to other cognitive states, and hence, this paper provides the first steps towards the development of a computational phenomenology of mental action and more broadly of our ability to monitor and control our own cognitive states. Future steps of this work will focus on fitting the model with qualitative, behavioural, and neural data.},
  file = {/home/kelly/Zotero/storage/N6NHPEII/Sandved-Smith et al. - 2021 - Towards a computational phenomenology of mental ac.pdf;/home/kelly/Zotero/storage/9P2UIPSY/6358635.html}
}

@article{schultz1997neural,
  title = {A Neural Substrate of Prediction and Reward},
  author = {Schultz, Wolfram and Dayan, Peter and Montague, P Read},
  year = {1997},
  journal = {Science (New York, N.Y.)},
  volume = {275},
  number = {5306},
  pages = {1593--1599},
  publisher = {{American Association for the Advancement of Science}}
}

@article{schultzResponsesMonkeyDopamine1993,
  title = {Responses of Monkey Dopamine Neurons to Reward and Conditioned Stimuli during Successive Steps of Learning a Delayed Response Task},
  author = {Schultz, W. and Apicella, P. and Ljungberg, T.},
  year = {1993},
  month = mar,
  journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  volume = {13},
  number = {3},
  pages = {900--913},
  issn = {0270-6474},
  abstract = {The present investigation had two aims: (1) to study responses of dopamine neurons to stimuli with attentional and motivational significance during several steps of learning a behavioral task, and (2) to study the activity of dopamine neurons during the performance of cognitive tasks known to be impaired after lesions of these neurons. Monkeys that had previously learned a simple reaction time task were trained to perform a spatial delayed response task via two intermediate tasks. During the learning of each new task, a total of 25\% of 76 dopamine neurons showed phasic responses to the delivery of primary liquid reward, whereas only 9\% of 163 neurons responded to this event once task performance was established. This produced an average population response during but not after learning of each task. Reward responses during learning were significantly more numerous and pronounced in area A10, as compared to areas A8 and A9. Dopamine neurons also showed phasic responses to the two conditioned stimuli. These were the instruction cue, which was the first stimulus in each trial and indicated the target of the upcoming arm movement (58\% of 76 neurons during and 44\% of 163 neurons after learning), and the trigger stimulus, which was a conditioned incentive stimulus predicting reward and eliciting a saccadic eye movement and an arm reaching movement (38\% of neurons during and 40\% after learning). None of the dopamine neurons showed sustained activity in the delay between the instruction and trigger stimuli that would resemble the activity of neurons in dopamine terminal areas, such as the striatum and frontal cortex. Thus, dopamine neurons respond phasically to alerting external stimuli with behavioral significance whose detection is crucial for learning and performing delayed response tasks. The lack of sustained activity suggests that dopamine neurons do not encode representational processes, such as working memory, expectation of external stimuli or reward, or preparation of movement. Rather, dopamine neurons are involved with transient changes of impulse activity in basic attentional and motivational processes underlying learning and cognitive behavior.},
  langid = {english},
  pmcid = {PMC6576600},
  pmid = {8441015},
  keywords = {Animals,Arm,Brain,Brain Mapping,Choice Behavior,{Conditioning, Operant},Corpus Striatum,Dopamine,Frontal Lobe,Learning,Macaca fascicularis,Male,Mesencephalon,Motivation,Motor Activity,Movement,Neurons,Reward,Saccades,Time Factors},
  file = {/home/kelly/Zotero/storage/427A8AYV/Schultz et al. - 1993 - Responses of monkey dopamine neurons to reward and.pdf}
}

@misc{seedorffMaybeMaximalGood2019,
  title = {Maybe Maximal: {{Good}} Enough Mixed Models Optimize Power While Controlling {{Type I}} Error},
  shorttitle = {Maybe Maximal},
  author = {Seedorff, Michael and Oleson, Jacob and McMurray, Bob},
  year = {2019},
  month = jan,
  publisher = {{PsyArXiv}},
  urldate = {2022-11-17},
  abstract = {Mixed effects models have become a critical tool in all areas of psychology and allied fields. This is due to their ability to account for multiple random factors, and their ability to handle proportional data in repeated measures designs. While substantial research has addressed how to structure fixed effects in such models there is less understanding of appropriate random effects structures. Recent work with linear models suggests the choice of random effects structures affects Type I error in such models (Barr, Levy, Scheepers, \& Tily, 2013; Matuschek, Kliegl, Vasishth, Baayen, \& Bates, 2017). This has not been examined for between subject effects, which are crucial for many areas of psychology, nor has this been examined in logistic models. Moreover, mixed models expose a number of researcher degrees of freedom: the decision to aggregate data or not, the manner in which degrees of freedom are computed, and what to do when models do not converge. However, the implications of these choices for power and Type I error are not well known. To address these issues, we conducted a series of Monte Carlo simulations which examined linear and logistic models in a mixed design with crossed random effects. These suggest that a consideration of the entire space of possible models using simple information criteria such as AIC leads to optimal power while holding Type I error constant. They also suggest data aggregation and the d.f, computation have minimal effects on Type I Error and Power, and they suggest appropriate approaches for dealing with non-convergence.},
  langid = {american},
  keywords = {Mixed Effects Models,Multilevel Models,Quantitative Methods,Random Effects,Repeated Measures,Social and Behavioral Sciences,Statistical Methods},
  file = {/home/kelly/Zotero/storage/NUMDII7R/Seedorff et al. - 2019 - Maybe maximal Good enough mixed models optimize p.pdf}
}

@article{shapiroMechanismsMindfulness2006,
  title = {Mechanisms of Mindfulness},
  author = {Shapiro, Shauna L. and Carlson, Linda E. and Astin, John A. and Freedman, Benedict},
  year = {2006},
  journal = {Journal of Clinical Psychology},
  volume = {62},
  number = {3},
  pages = {373--386},
  issn = {1097-4679},
  urldate = {2023-07-04},
  abstract = {Recently, the psychological construct mindfulness has received a great deal of attention. The majority of research has focused on clinical studies to evaluate the efficacy of mindfulness-based interventions. This line of research has led to promising data suggesting mindfulness-based interventions are effective for treatment of both psychological and physical symptoms. However, an equally important direction for future research is to investigate questions concerning mechanisms of action underlying mindfulness-based interventions. This theoretical paper proposes a model of mindfulness, in an effort to elucidate potential mechanisms to explain how mindfulness affects positive change. Potential implications and future directions for the empirical study of mechanisms involved in mindfulness are addressed. \textcopyright{} 2005 Wiley Periodicals, Inc. J Clin Psychol 62: 373\textendash 386, 2006.},
  copyright = {Copyright \textcopyright{} 2006 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/TYH9SSBR/jclp.html}
}

@article{shohamyLdopaImpairsLearning2006,
  title = {L-Dopa Impairs Learning, but Spares Generalization, in {{Parkinson}}'s Disease},
  author = {Shohamy, Daphna and Myers, Catherine E. and Geghman, Kindiya D. and Sage, Jacob and Gluck, Mark A.},
  year = {2006},
  month = jan,
  journal = {Neuropsychologia},
  volume = {44},
  number = {5},
  pages = {774--784},
  issn = {0028-3932},
  urldate = {2023-07-04},
  abstract = {In this study we examined the effect of dopaminergic modulation on learning and memory. Parkinson's patients were tested `on' versus `off' dopaminergic medication, using a two-phase learning and transfer task. We found that dopaminergic medication was associated with impaired learning of an incrementally acquired concurrent discrimination task, while patients withdrawn from dopaminergic medication performed as well as controls. In addition, we found a dissociation of the effect of medication within a single two-phase task: patients tested `on' medication were not impaired at the ability to generalize based on learned information. The deficit among medicated patients appeared to be related specifically to the concurrent, incremental, feedback-based nature of the task: such a deficit was not found in a version of the task in which demands for concurrent error-processing learning were reduced. Taken together with a growing body of evidence emphasizing a role for midbrain dopamine in error-correcting, feedback-based learning processes, the present results suggest a framework for understanding previously conflicting results regarding the effect of medication on learning and memory in Parkinson's disease.},
  langid = {english},
  keywords = {Basal ganglia,Cognition,Dopamine,Learning,Memory},
  file = {/home/kelly/Zotero/storage/5D4ZQMF7/Shohamy et al. - 2006 - l-dopa impairs learning, but spares generalization.pdf;/home/kelly/Zotero/storage/QTHQSFIY/S0028393205002630.html}
}

@article{smithHabitFormation2016,
  title = {Habit Formation},
  author = {Smith, Kyle S. and Graybiel, Ann M.},
  year = {2016},
  month = mar,
  journal = {Dialogues in Clinical Neuroscience},
  volume = {18},
  number = {1},
  pages = {33--43},
  issn = {1294-8322},
  urldate = {2023-07-04},
  abstract = {Habits, both good ones and bad ones, are pervasive in animal behavior. Important frameworks have been developed to understand habits through psychological and neurobiological studies. This work has given us a rich understanding of brain networks that promote habits, and has also helped us to understand what constitutes a habitual behavior as opposed to a behavior that is more flexible and prospective. Mounting evidence from studies using neural recording methods suggests that habit formation is not a simple process. We review this evidence and take the position that habits could be sculpted from multiple dissociable changes in neural activity. These changes occur across multiple brain regions and even within single brain regions. This strategy of classifying components of a habit based on different brain signals provides a potentially useful new way to conceive of disorders that involve overly fixed behaviors as arising from different potential dysfunctions within the brain's habit network.},
  pmcid = {PMC4826769},
  pmid = {27069378},
  file = {/home/kelly/Zotero/storage/88THY4X8/Smith and Graybiel - 2016 - Habit formation.pdf}
}

@inproceedings{spragueEyeMovementsReward2003,
  title = {Eye Movements for Reward Maximization},
  booktitle = {Proceedings of the 16th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Sprague, Nathan and Ballard, Dana},
  year = {2003},
  month = dec,
  series = {{{NIPS}}'03},
  pages = {1467--1474},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  urldate = {2023-04-12},
  abstract = {Recent eye tracking studies in natural tasks suggest that there is a tight link between eye movements and goal directed motor actions. However, most existing models of human eye movements provide a bottom up account that relates visual attention to attributes of the visual scene. The purpose of this paper is to introduce a new model of human eye movements that directly ties eye movements to the ongoing demands of behavior. The basic idea is that eye movements serve to reduce uncertainty about environmental variables that are task relevant. A value is assigned to an eye movement by estimating the expected cost of the uncertainty that will result if the movement is not made. If there are several candidate eye movements, the one with the highest expected value is chosen. The model is illustrated using a humanoid graphic figure that navigates on a sidewalk in a virtual urban environment. Simulations show our protocol is superior to a simple round robin scheduling mechanism.},
  file = {/home/kelly/Zotero/storage/FWFP936R/Sprague and Ballard - 2003 - Eye movements for reward maximization.pdf}
}

@misc{standevelopmentteamRStanInterfaceStan2023,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  year = {2023}
}

@misc{standevelopmentteamStanModelingLanguage,
  title = {Stan {{Modeling Language Users Guide}} and {{Reference Manual}}},
  author = {Stan Development Team}
}

@article{stillmanDispositionalMindfulnessAssociated2014,
  title = {Dispositional Mindfulness Is Associated with Reduced Implicit Learning},
  author = {Stillman, Chelsea M. and Feldman, Halley and Wambach, Caroline G. and Howard, James H. and Howard, Darlene V.},
  year = {2014},
  month = aug,
  journal = {Consciousness and Cognition},
  volume = {28},
  pages = {141--150},
  issn = {1053-8100},
  urldate = {2023-06-12},
  abstract = {Behavioral and neuroimaging evidence suggest that mindfulness exerts its salutary effects by disengaging habitual processes supported by subcortical regions and increasing effortful control processes supported by the frontal lobes. Here we investigated whether individual differences in dispositional mindfulness relate to performance on implicit sequence learning tasks in which optimal learning may in fact be impeded by the engagement of effortful control processes. We report results from two studies where participants completed a widely used questionnaire assessing mindfulness and one of two implicit sequence learning tasks. Learning was quantified using two commonly used measures of sequence learning. In both studies we detected a negative relationship between mindfulness and sequence learning, and the relationship was consistent across both learning measures. Our results, the first to show a negative relationship between mindfulness and implicit sequence learning, suggest that the beneficial effects of mindfulness do not extend to all cognitive functions.},
  langid = {english},
  keywords = {Implicit learning,Mindfulness,Serial response time task},
  file = {/home/kelly/Zotero/storage/B4DJR9IS/Stillman et al. - 2014 - Dispositional mindfulness is associated with reduc.pdf;/home/kelly/Zotero/storage/QMEJVQLB/S1053810014001019.html}
}

@book{sutton2018reinforcement,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2018},
  publisher = {{MIT press}}
}

@article{uddinStructureFunctionHuman2017,
  title = {Structure and Function of the Human Insula},
  author = {Uddin, Lucina Q. and Nomi, Jason S. and {Hebert-Seropian}, Benjamin and Ghaziri, Jimmy and Boucher, Olivier},
  year = {2017},
  month = jul,
  journal = {Journal of clinical neurophysiology : official publication of the American Electroencephalographic Society},
  volume = {34},
  number = {4},
  pages = {300--306},
  issn = {0736-0258},
  urldate = {2023-06-23},
  abstract = {The insular cortex, or ``Island of Reil'', is hidden deep within the lateral sulcus of the brain. Subdivisions within the insula have been identified on the basis of cytoarchitectonics, sulcal landmarks, and connectivity. Depending on the parcellation technique employed, the insula can be divided into anywhere between 2 and 13 distinct subdivisions. The insula subserves a wide variety of functions in humans ranging from sensory and affective processing to high-level cognition. Here we provide a concise summary of known structural and functional features of the human insular cortex with a focus on lesion case studies and recent neuroimaging evidence for considerable functional heterogeneity of this brain region.},
  pmcid = {PMC6032992},
  pmid = {28644199},
  file = {/home/kelly/Zotero/storage/7WI9T8Z3/Uddin et al. - 2017 - Structure and function of the human insula.pdf}
}

@article{vaidyaNeuralRepresentationAbstract2021,
  title = {Neural Representation of Abstract Task Structure during Generalization},
  author = {Vaidya, Avinash R and Jones, Henry M and Castillo, Johanny and Badre, David},
  editor = {Liljeholm, Mimi and Ivry, Richard B and Ranganath, Charan and Michelmann, Sebastian},
  year = {2021},
  month = mar,
  journal = {eLife},
  volume = {10},
  pages = {e63226},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  urldate = {2021-11-04},
  abstract = {Cognitive models in psychology and neuroscience widely assume that the human brain maintains an abstract representation of tasks. This assumption is fundamental to theories explaining how we learn quickly, think creatively, and act flexibly. However, neural evidence for a verifiably generative abstract task representation has been lacking. Here, we report an experimental paradigm that requires forming such a representation to act adaptively in novel conditions without feedback. Using functional magnetic resonance imaging, we observed that abstract task structure was represented within left mid-lateral prefrontal cortex, bilateral precuneus, and inferior parietal cortex. These results provide support for the neural instantiation of the long-supposed abstract task representation in a setting where we can verify its influence. Such a representation can afford massive expansions of behavioral flexibility without additional experience, a vital characteristic of human cognition.},
  keywords = {cognition,decision-making,inference,learning,psychology,reinforcement},
  file = {/home/kelly/Zotero/storage/STCX8JJ6/Vaidya et al. - 2021 - Neural representation of abstract task structure d.pdf}
}

@article{vankempenDopamineInfluencesAttentional2022,
  title = {Dopamine Influences Attentional Rate Modulation in {{Macaque}} Posterior Parietal Cortex},
  author = {{van Kempen}, Jochem and Brandt, Christian and Distler, Claudia and Bellgrove, Mark A. and Thiele, Alexander},
  year = {2022},
  month = apr,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {1--14},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  urldate = {2022-07-12},
  abstract = {Cognitive neuroscience has made great strides in understanding the neural substrates of attention, but our understanding of its neuropharmacology remains incomplete. Although dopamine has historically been studied in relation to frontal functioning, emerging evidence suggests important dopaminergic influences in parietal cortex. We recorded single- and multi-unit activity whilst iontophoretically administering dopaminergic agonists and antagonists while rhesus macaques performed a spatial attention task. Out of 88 units, 50 revealed activity modulation by drug administration. Dopamine inhibited firing rates according to an inverted-U shaped dose\textendash response curve and increased gain variability. D1 receptor antagonists diminished firing rates according to a monotonic function and interacted with attention modulating gain variability. Finally, both drugs decreased the pupil light reflex. These data show that dopamine shapes neuronal responses and modulates aspects of attentional processing in parietal cortex.},
  copyright = {2022 The Author(s)},
  langid = {english},
  file = {/home/kelly/Zotero/storage/T9W36DG2/van Kempen et al. - 2022 - Dopamine influences attentional rate modulation in.pdf;/home/kelly/Zotero/storage/4VKWVB2U/s41598-022-10634-w.html}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  journal = {Statistics and Computing},
  volume = {27},
  number = {5},
  pages = {1413--1432},
  issn = {1573-1375},
  urldate = {2023-01-27},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  langid = {english},
  keywords = {Bayesian computation,K-fold cross-validation,Leave-one-out cross-validation (LOO),Pareto smoothed importance sampling (PSIS),Stan,Widely applicable information criterion (WAIC)},
  file = {/home/kelly/Zotero/storage/KMEUHDST/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf}
}

@incollection{verhoevenRoleHabitsMaladaptive2018,
  title = {The {{Role}} of {{Habits}} in {{Maladaptive Behaviour}} and {{Therapeutic Interventions}}},
  booktitle = {The {{Psychology}} of {{Habit}}: {{Theory}}, {{Mechanisms}}, {{Change}}, and {{Contexts}}},
  author = {Verhoeven, Aukje and {de Wit}, Sanne},
  editor = {Verplanken, Bas},
  year = {2018},
  pages = {285--303},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  urldate = {2023-06-07},
  abstract = {Habits prevent flexible behavioural adjustments when the consequences are no longer desirable or even harmful, and as such may play an important role in health-related behaviours but also in psychopathologies like substance abuse or obsessive-compulsive disorder. Furthermore, increasing evidence suggests that some people are more prone than others to act out of habit, and experimental research has linked this `habit propensity' to certain psychopathologies. We will provide a review of recent research into maladaptive habits in health- and clinical psychology and suggest that these two fields can benefit from each other's methodologies and insights. We will discuss the theoretical and practical implications for therapeutic interventions, and point out promising avenues for future investigations.},
  isbn = {978-3-319-97529-0},
  langid = {english},
  keywords = {Cognitive-behavioural treatment,Dual-process theory,Habit propensity,Implementation intention,Outcome-devaluation test,Slips-of-action test},
  file = {/home/kelly/Zotero/storage/E5WAJZUY/Verhoeven and de Wit - 2018 - The Role of Habits in Maladaptive Behaviour and Th.pdf}
}

@article{waeltiDopamineResponsesComply2001,
  title = {Dopamine Responses Comply with Basic Assumptions of Formal Learning Theory},
  author = {Waelti, Pascale and Dickinson, Anthony and Schultz, Wolfram},
  year = {2001},
  month = jul,
  journal = {Nature},
  volume = {412},
  number = {6842},
  pages = {43--48},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  urldate = {2023-07-04},
  abstract = {According to contemporary learning theories, the discrepancy, or error, between the actual and predicted reward determines whether learning occurs when a stimulus is paired with a reward. The role of prediction errors is directly demonstrated by the observation that learning is blocked when the stimulus is paired with a fully predicted reward. By using this blocking procedure, we show that the responses of dopamine neurons to conditioned stimuli was governed differentially by the occurrence of reward prediction errors rather than stimulus\textendash reward associations alone, as was the learning of behavioural reactions. Both behavioural and neuronal learning occurred predominantly when dopamine neurons registered a reward prediction error at the time of the reward. Our data indicate that the use of analytical tests derived from formal behavioural learning theory provides a powerful approach for studying the role of single neurons in learning.},
  copyright = {2001 Macmillan Magazines Ltd.},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/home/kelly/Zotero/storage/X5IHVYZP/Waelti et al. - 2001 - Dopamine responses comply with basic assumptions o.pdf}
}

@article{wickensDopaminergicMechanismsActions2007,
  title = {Dopaminergic {{Mechanisms}} in {{Actions}} and {{Habits}}},
  author = {Wickens, Jeffery R. and Horvitz, Jon C. and Costa, Rui M. and Killcross, Simon},
  year = {2007},
  month = aug,
  journal = {Journal of Neuroscience},
  volume = {27},
  number = {31},
  pages = {8181--8183},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  urldate = {2023-06-16},
  abstract = {Recent studies suggest new ways to interpret dopaminergic actions in goal-directed performance and habitual responding. In the early stages of learning dopamine plays an essential role, but with extended training dopamine appears to play a decreasing role in response expression. Experimental manipulation of dopamine levels alters the correlation of cortical and striatal neural activity in behaving animals, and these dopamine-dependent changes in corticostriatal correlations may be reflected in changes in action selection in the basal ganglia. Consistent with this hypothesis, changes in dopamine signaling brought about by sensitization with amphetamine mimic the transition from goal-directed to habit-based instrumental performance. At the cellular level, dopamine-dependent synaptic plasticity may be important initially, and subsequently lead to more persistent changes that no longer require dopamine. The locus of these actions within the cortical and corticostriatal circuitry is a focus on ongoing research.},
  chapter = {Mini-Review},
  copyright = {Copyright \textcopyright{} 2007 Society for Neuroscience 0270-6474/07/278181-03\$15.00/0},
  langid = {english},
  pmid = {17670964},
  keywords = {action,cortex,corticostriatal,dopamine,habit,learning,reinforcement,striatum},
  file = {/home/kelly/Zotero/storage/3DVQS3LU/Wickens et al. - 2007 - Dopaminergic Mechanisms in Actions and Habits.pdf}
}

@article{wieckiNeurocomputationalModelsMotor2010,
  title = {Neurocomputational Models of Motor and Cognitive Deficits in {{Parkinson}}'s Disease},
  author = {Wiecki, Thomas V. and Frank, Michael J.},
  year = {2010},
  journal = {Progress in Brain Research},
  volume = {183},
  pages = {275--297},
  issn = {1875-7855},
  abstract = {We review the contributions of biologically constrained computational models to our understanding of motor and cognitive deficits in Parkinson's disease (PD). The loss of dopaminergic neurons innervating the striatum in PD, and the well-established role of dopamine (DA) in reinforcement learning (RL), enable neural network models of the basal ganglia (BG) to derive concrete and testable predictions. We focus in this review on one simple underlying principle - the notion that reduced DA increases activity and causes long-term potentiation in the indirect pathway of the BG. We show how this theory can provide a unified account of diverse and seemingly unrelated phenomena in PD including progressive motor degeneration as well as cognitive deficits in RL, decision making and working memory. DA replacement therapy and deep brain stimulation can alleviate some aspects of these impairments, but can actually introduce negative effects such as motor dyskinesias and cognitive impulsivity. We discuss these treatment effects in terms of modulation of specific mechanisms within the computational framework. In addition, we review neurocomputational interpretations of increased impulsivity in the face of response conflict in patients with deep-brain-stimulation.},
  langid = {english},
  pmid = {20696325},
  keywords = {Animals,Basal Ganglia,Cognition,Computer Simulation,Dopamine,Humans,Learning,Levodopa,Memory,{Models, Neurological},Neural Inhibition,Neural Pathways,Parkinson Disease}
}

@article{willuhnExcessiveCocaineUse2014,
  title = {Excessive Cocaine Use Results from Decreased Phasic Dopamine Signaling in the Striatum},
  author = {Willuhn, Ingo and Burgeno, Lauren M. and Groblewski, Peter A. and Phillips, Paul E. M.},
  year = {2014},
  month = may,
  journal = {Nature neuroscience},
  volume = {17},
  number = {5},
  pages = {704--709},
  issn = {1097-6256},
  urldate = {2023-04-14},
  abstract = {Drug addiction is a neuropsychiatric disorder marked by escalating drug use. Dopamine neurotransmission in the ventromedial striatum (VMS) mediates acute reinforcing effects of abused drugs, but with protracted use the dorsolateral striatum (DLS) is thought to assume control over drug seeking. We measured striatal dopamine release during a cocaine self-administration regimen that produced escalation of drug taking in rats. Surprisingly, we found that phasic dopamine decreased in both regions as the rate of cocaine intake increased; with the decrement in dopamine in the VMS significantly correlated with the rate of escalation. Administration of the dopamine precursor L-DOPA at a dose that replenished dopamine signaling in the VMS reversed escalation, thereby demonstrating the causal relationship between diminished dopamine transmission and excessive drug use. Thus, together these data provide mechanistic and therapeutic insight into the excessive drug intake that emerges following protracted use.},
  pmcid = {PMC4714770},
  pmid = {24705184},
  file = {/home/kelly/Zotero/storage/VYY7TX2J/Willuhn et al. - 2014 - Excessive cocaine use results from decreased phasi.pdf}
}

@article{wunderlichDopamineEnhancesModelBased2012,
  title = {Dopamine {{Enhances Model-Based}} over {{Model-Free Choice Behavior}}},
  author = {Wunderlich, Klaus and Smittenaar, Peter and Dolan, Raymond J.},
  year = {2012},
  month = aug,
  journal = {Neuron},
  volume = {75},
  number = {3},
  pages = {418--424},
  issn = {0896-6273},
  urldate = {2023-04-19},
  abstract = {Decision making is often considered to arise out of contributions from a model-free habitual system and a model-based goal-directed system. Here, we investigated the effect of a dopamine manipulation on the degree to which either system contributes to instrumental behavior in a two-stage Markov decision task, which has been shown to discriminate model-free from model-based control. We found increased dopamine levels promote model-based over model-free choice.},
  langid = {english},
  file = {/home/kelly/Zotero/storage/5QM6RUX3/Wunderlich et al. - 2012 - Dopamine Enhances Model-Based over Model-Free Choi.pdf;/home/kelly/Zotero/storage/2P7A9FLD/S0896627312005272.html}
}

@article{wunderlichDopamineEnhancesModelBased2012a,
  title = {Dopamine {{Enhances Model-Based}} over {{Model-Free Choice Behavior}}},
  author = {Wunderlich, Klaus and Smittenaar, Peter and Dolan, Raymond~J.},
  year = {2012},
  month = aug,
  journal = {Neuron},
  volume = {75},
  number = {3-4},
  pages = {418--424},
  issn = {0896-6273},
  urldate = {2023-07-03},
  abstract = {Decision making is often considered to arise out of contributions from a model-free habitual system and a model-based goal-directed system. Here, we investigated the effect of a dopamine manipulation on the degree to which either system contributes to instrumental behavior in a two-stage Markov decision task, which has been shown to discriminate model-free from model-based control. We found increased dopamine levels promote model-based over model-free choice., {$\blackpointerright$} Dopamine increases relative degree of model-based to model-free behavior, Decision making arises out of contributions from model-free habitual and model-based goal-directed systems. Wunderlich et~al. investigate how dopamine affects each system to contribute to instrumental behavior, finding that increased dopamine levels preferentially promote model-based goal-directed choice.},
  pmcid = {PMC3417237},
  pmid = {22884326},
  file = {/home/kelly/Zotero/storage/KWY6SWWE/Wunderlich et al. - 2012 - Dopamine Enhances Model-Based over Model-Free Choi.pdf}
}

@article{yooHowWorkingMemory2022,
  title = {How {{Working Memory}} and {{Reinforcement Learning Are Intertwined}}: {{A Cognitive}}, {{Neural}}, and {{Computational Perspective}}},
  shorttitle = {How {{Working Memory}} and {{Reinforcement Learning Are Intertwined}}},
  author = {Yoo, Aspen H. and Collins, Anne G. E.},
  year = {2022},
  month = mar,
  journal = {Journal of Cognitive Neuroscience},
  volume = {34},
  number = {4},
  pages = {551--568},
  issn = {0898-929X},
  urldate = {2023-04-19},
  abstract = {Reinforcement learning and working memory are two core processes of human cognition and are often considered cognitively, neuroscientifically, and algorithmically distinct. Here, we show that the brain networks that support them actually overlap significantly and that they are less distinct cognitive processes than often assumed. We review literature demonstrating the benefits of considering each process to explain properties of the other and highlight recent work investigating their more complex interactions. We discuss how future research in both computational and cognitive sciences can benefit from one another, suggesting that a key missing piece for artificial agents to learn to behave with more human-like efficiency is taking working memory's role in learning seriously. This review highlights the risks of neglecting the interplay between different processes when studying human behavior (in particular when considering individual differences). We emphasize the importance of investigating these dynamics to build a comprehensive understanding of human cognition.},
  file = {/home/kelly/Zotero/storage/FTV75XRN/Yoo and Collins - 2022 - How Working Memory and Reinforcement Learning Are .pdf;/home/kelly/Zotero/storage/Q25EVZSV/How-Working-Memory-and-Reinforcement-Learning-Are.html}
}
